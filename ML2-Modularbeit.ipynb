{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8168e98c",
   "metadata": {},
   "source": [
    "# Timon Spichtinger Machine Learning 2 Modularbeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2222d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add5d4d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0cab2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83028502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f38f94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e34932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8205d9f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27268009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c809822e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "113ca418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import EMNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch\n",
    "import importlib\n",
    "from Datensatz import get_emnist_test_train, show_random_samples\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3bf0cf",
   "metadata": {},
   "source": [
    "Train und Testdaten werden aus Emnist-Datensatz geladen. Falls es zuwenige gibt werden die restlichen Augmentiert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9b5f04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ziel-ASCII: [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109]\n",
      "Anzahl Zielklassen: 36\n",
      "‚ö†Ô∏è Klasse B: nur 3878 echte Bilder ‚Äì augmentiere 2122 zus√§tzlich.\n",
      "‚ö†Ô∏è Klasse D: nur 4562 echte Bilder ‚Äì augmentiere 1438 zus√§tzlich.\n",
      "‚ö†Ô∏è Klasse E: nur 4934 echte Bilder ‚Äì augmentiere 1066 zus√§tzlich.\n",
      "‚ö†Ô∏è Klasse G: nur 2517 echte Bilder ‚Äì augmentiere 3483 zus√§tzlich.\n",
      "‚ö†Ô∏è Klasse H: nur 3152 echte Bilder ‚Äì augmentiere 2848 zus√§tzlich.\n",
      "‚ö†Ô∏è Klasse J: nur 3762 echte Bilder ‚Äì augmentiere 2238 zus√§tzlich.\n",
      "‚ö†Ô∏è Klasse K: nur 2468 echte Bilder ‚Äì augmentiere 3532 zus√§tzlich.\n",
      "‚ö†Ô∏è Klasse L: nur 5076 echte Bilder ‚Äì augmentiere 924 zus√§tzlich.\n",
      "‚ö†Ô∏è Klasse b: nur 5159 echte Bilder ‚Äì augmentiere 841 zus√§tzlich.\n",
      "‚ö†Ô∏è Klasse c: nur 2854 echte Bilder ‚Äì augmentiere 3146 zus√§tzlich.\n",
      "‚ö†Ô∏è Klasse f: nur 2561 echte Bilder ‚Äì augmentiere 3439 zus√§tzlich.\n",
      "‚ö†Ô∏è Klasse g: nur 3687 echte Bilder ‚Äì augmentiere 2313 zus√§tzlich.\n",
      "‚ö†Ô∏è Klasse i: nur 2725 echte Bilder ‚Äì augmentiere 3275 zus√§tzlich.\n",
      "‚ö†Ô∏è Klasse j: nur 1896 echte Bilder ‚Äì augmentiere 4104 zus√§tzlich.\n",
      "‚ö†Ô∏è Klasse k: nur 2491 echte Bilder ‚Äì augmentiere 3509 zus√§tzlich.\n",
      "‚ö†Ô∏è Klasse m: nur 2645 echte Bilder ‚Äì augmentiere 3355 zus√§tzlich.\n",
      "‚úÖ Trainingsdaten: torch.Size([180000, 1, 28, 28]) torch.Size([180000])\n",
      "‚úÖ Testdaten: torch.Size([36000, 1, 28, 28]) torch.Size([36000])\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test,class_list = get_emnist_test_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65711290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58605ffa",
   "metadata": {},
   "source": [
    "Stichprobe, ob der Datensatz passt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39fe5cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x200 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_samples(X_test, y_test, class_list, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295aecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae2f5e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/timon/ML2Modularbeit/env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import optuna\n",
    "from Klassifikator import get_objective, ResNet18, EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c18fcdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ger√§t\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c7b06d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:26:36,444] A new study created in memory with name: no-name-1b050c12-391c-4cd8-9823-72a6513e207c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Epoch 1: Val Loss = 0.4947\n",
      "üìâ Epoch 2: Val Loss = 0.3946\n",
      "üìâ Epoch 3: Val Loss = 0.3696\n",
      "üìâ Epoch 4: Val Loss = 0.3640\n",
      "üìâ Epoch 5: Val Loss = 0.3630\n",
      "üìâ Epoch 6: Val Loss = 0.3552\n",
      "üìâ Epoch 7: Val Loss = 0.3666\n",
      "üìâ Epoch 8: Val Loss = 0.3778\n",
      "üìâ Epoch 9: Val Loss = 0.3697\n",
      "‚õî Early Stopping in Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:29:50,061] Trial 0 finished with value: 0.8543888888888889 and parameters: {'batch_size': 144, 'lr': 0.020764818644962976, 'momentum': 0.6901517686431473, 'step_size': 5, 'gamma': 0.8446610713361149}. Best is trial 0 with value: 0.8543888888888889.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚õî Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:30:29,152] Trial 1 finished with value: 0.8675 and parameters: {'batch_size': 64, 'lr': 0.0002626476455093473, 'momentum': 0.7742388161851498, 'step_size': 5, 'gamma': 0.6966457077817843}. Best is trial 1 with value: 0.8675.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚õî Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:30:49,676] Trial 2 finished with value: 0.8667777777777778 and parameters: {'batch_size': 144, 'lr': 0.0005299509572357056, 'momentum': 0.6529835506521925, 'step_size': 4, 'gamma': 0.6401312796271024}. Best is trial 1 with value: 0.8675.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚õî Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:31:28,552] Trial 3 finished with value: 0.86625 and parameters: {'batch_size': 64, 'lr': 0.0002688841248801269, 'momentum': 0.8417745238951722, 'step_size': 3, 'gamma': 0.6445902290363521}. Best is trial 1 with value: 0.8675.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚õî Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:32:07,467] Trial 4 finished with value: 0.8660833333333333 and parameters: {'batch_size': 64, 'lr': 0.00011387914347155919, 'momentum': 0.7024452859301568, 'step_size': 4, 'gamma': 0.5947190142501897}. Best is trial 1 with value: 0.8675.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚õî Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:32:23,658] Trial 5 finished with value: 0.8665555555555555 and parameters: {'batch_size': 256, 'lr': 0.000125472361981672, 'momentum': 0.6964429260164438, 'step_size': 4, 'gamma': 0.5696984435343417}. Best is trial 1 with value: 0.8675.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚õî Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:32:44,210] Trial 6 finished with value: 0.8511388888888889 and parameters: {'batch_size': 144, 'lr': 0.049900454432328024, 'momentum': 0.765390092149725, 'step_size': 5, 'gamma': 0.7027098266730037}. Best is trial 1 with value: 0.8675.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚õî Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:33:00,399] Trial 7 finished with value: 0.869 and parameters: {'batch_size': 256, 'lr': 0.0005543410708730624, 'momentum': 0.9373151936144546, 'step_size': 4, 'gamma': 0.6115812631807419}. Best is trial 7 with value: 0.869.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚õî Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:33:20,900] Trial 8 finished with value: 0.8690277777777777 and parameters: {'batch_size': 144, 'lr': 0.00018784872833566514, 'momentum': 0.7216490889652839, 'step_size': 4, 'gamma': 0.843042780832338}. Best is trial 8 with value: 0.8690277777777777.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚õî Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:33:36,985] Trial 9 finished with value: 0.8677222222222222 and parameters: {'batch_size': 256, 'lr': 0.02323977172081824, 'momentum': 0.6295707832606687, 'step_size': 4, 'gamma': 0.7800745027767458}. Best is trial 8 with value: 0.8690277777777777.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚õî Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:33:58,265] Trial 10 finished with value: 0.8698611111111111 and parameters: {'batch_size': 128, 'lr': 0.003021825861562867, 'momentum': 0.8428798752491594, 'step_size': 2, 'gamma': 0.9331893268725289}. Best is trial 10 with value: 0.8698611111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚õî Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:34:19,752] Trial 11 finished with value: 0.8669722222222223 and parameters: {'batch_size': 128, 'lr': 0.003093141654967733, 'momentum': 0.8650018189862356, 'step_size': 2, 'gamma': 0.9445900459081065}. Best is trial 10 with value: 0.8698611111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚õî Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:34:41,054] Trial 12 finished with value: 0.86425 and parameters: {'batch_size': 128, 'lr': 0.0029921156750480774, 'momentum': 0.864400117296005, 'step_size': 2, 'gamma': 0.9396676738130931}. Best is trial 10 with value: 0.8698611111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚õî Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:35:02,365] Trial 13 finished with value: 0.8667777777777778 and parameters: {'batch_size': 128, 'lr': 0.001578025287044887, 'momentum': 0.826344389108888, 'step_size': 3, 'gamma': 0.8503390392400593}. Best is trial 10 with value: 0.8698611111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚õî Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:35:22,957] Trial 14 finished with value: 0.8495833333333334 and parameters: {'batch_size': 144, 'lr': 0.009871387509443321, 'momentum': 0.9399936856950271, 'step_size': 3, 'gamma': 0.8684243458346163}. Best is trial 10 with value: 0.8698611111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚õî Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:35:44,215] Trial 15 finished with value: 0.8695277777777778 and parameters: {'batch_size': 128, 'lr': 0.001190563370932246, 'momentum': 0.7392689792699053, 'step_size': 2, 'gamma': 0.7663275804093992}. Best is trial 10 with value: 0.8698611111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚õî Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:36:05,471] Trial 16 finished with value: 0.8697777777777778 and parameters: {'batch_size': 128, 'lr': 0.0012623878832816835, 'momentum': 0.7477818754802374, 'step_size': 2, 'gamma': 0.5010048212323668}. Best is trial 10 with value: 0.8698611111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚õî Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:36:26,684] Trial 17 finished with value: 0.8641111111111112 and parameters: {'batch_size': 128, 'lr': 0.00728737145333502, 'momentum': 0.808100973377723, 'step_size': 2, 'gamma': 0.5019012799488144}. Best is trial 10 with value: 0.8698611111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚õî Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:36:48,163] Trial 18 finished with value: 0.8668888888888889 and parameters: {'batch_size': 128, 'lr': 0.0011311670383583943, 'momentum': 0.8944176707165965, 'step_size': 3, 'gamma': 0.5215908483754571}. Best is trial 10 with value: 0.8698611111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚õî Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:37:09,359] Trial 19 finished with value: 0.868 and parameters: {'batch_size': 128, 'lr': 0.006377653704720029, 'momentum': 0.7986814031392421, 'step_size': 2, 'gamma': 0.7650006004613287}. Best is trial 10 with value: 0.8698611111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Beste Hyperparameter:\n",
      "batch_size: 128\n",
      "lr: 0.003021825861562867\n",
      "momentum: 0.8428798752491594\n",
      "step_size: 2\n",
      "gamma: 0.9331893268725289\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Optuna-Studie starten\n",
    "# -----------------------------\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(get_objective(\n",
    "          train_dataset=train_dataset,\n",
    "          test_dataset=test_dataset,\n",
    "          device=device,\n",
    "          model=ResNet18(num_classes=len(class_list)).to(device),\n",
    "          early_stopping=EarlyStopping(patience=4)), n_trials=20)\n",
    "\n",
    "# Beste Parameter anzeigen\n",
    "print(\"üéØ Beste Hyperparameter:\")\n",
    "for k, v in study.best_params.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdf5b4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Finales Training mit besten Parametern \n",
    "# -----------------------------\n",
    "best_params = study.best_params\n",
    "train_loader = DataLoader(train_dataset, batch_size=best_params[\"batch_size\"], shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=best_params[\"batch_size\"], shuffle=False)\n",
    "\n",
    "model = ResNet18(num_classes=len(class_list)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=best_params[\"lr\"], momentum=best_params[\"momentum\"])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=best_params[\"step_size\"], gamma=best_params[\"gamma\"])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e123029",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        if (i + 1) % 200 == 0:\n",
    "            print(f\"üîÅ Epoch {epoch+1}, Step {i+1}/{len(train_loader)}: Batch Loss = {loss.item():.4f}\")\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # Validierung\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "    val_loss /= len(test_loader)\n",
    "    train_acc = 100.0 * correct_train / total_train\n",
    "    val_acc = 100.0 * correct_val / total_val\n",
    "\n",
    "    print(f\"üìä Epoch {epoch+1}: Train Acc = {train_acc:.2f}%, Val Acc = {val_acc:.2f}%, Val Loss = {val_loss:.4f}, LR = {scheduler.get_last_lr()}\")\n",
    "    early_stopping = EarlyStopping()\n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(f\"üõë Early stopping ausgel√∂st bei Epoch {epoch+1} (Val Loss: {val_loss:.4f})\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bef864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modell speichern\n",
    "torch.save(model.state_dict(), './resnet18_best_hyperparams.pth')\n",
    "print(\"‚úÖ Modell gespeichert.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4baf65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gesamtgenauigkeit des Netzwerks: 3.17 %\n",
      "Genauigkeit f√ºr Klasse 48: 0.00 %\n",
      "Genauigkeit f√ºr Klasse 49: 0.00 %\n",
      "Genauigkeit f√ºr Klasse 50: 0.00 %\n",
      "Genauigkeit f√ºr Klasse 51: 0.00 %\n",
      "Genauigkeit f√ºr Klasse 52: 0.00 %\n",
      "Genauigkeit f√ºr Klasse 53: 0.00 %\n",
      "Genauigkeit f√ºr Klasse 54: 0.00 %\n",
      "Genauigkeit f√ºr Klasse 55: 0.00 %\n",
      "Genauigkeit f√ºr Klasse 56: 0.00 %\n",
      "Genauigkeit f√ºr Klasse 57: 0.00 %\n",
      "Genauigkeit f√ºr Klasse 65: 0.00 %\n",
      "Genauigkeit f√ºr Klasse 66: 11.50 %\n",
      "Genauigkeit f√ºr Klasse 67: 0.00 %\n",
      "Genauigkeit f√ºr Klasse 68: 0.00 %\n",
      "Genauigkeit f√ºr Klasse 69: 0.00 %\n",
      "Genauigkeit f√ºr Klasse 70: 0.00 %\n",
      "Genauigkeit f√ºr Klasse 71: 0.00 %\n",
      "Genauigkeit f√ºr Klasse 72: 2.70 %\n",
      "Genauigkeit f√ºr Klasse 73: 0.00 %\n",
      "Genauigkeit f√ºr Klasse 74: 3.00 %\n",
      "Genauigkeit f√ºr Klasse 75: 0.00 %\n",
      "Genauigkeit f√ºr Klasse 76: 0.00 %\n",
      "Genauigkeit f√ºr Klasse 77: 0.00 %\n",
      "Genauigkeit f√ºr Klasse 97: 0.00 %\n",
      "Genauigkeit f√ºr Klasse 98: 0.00 %\n",
      "Genauigkeit f√ºr Klasse 99: 0.00 %\n",
      "Genauigkeit f√ºr Klasse 100: 0.00 %\n",
      "Genauigkeit f√ºr Klasse 101: 97.00 %\n",
      "Genauigkeit f√ºr Klasse 102: 0.00 %\n",
      "Genauigkeit f√ºr Klasse 103: 0.00 %\n",
      "Genauigkeit f√ºr Klasse 104: 0.00 %\n",
      "Genauigkeit f√ºr Klasse 105: 0.00 %\n",
      "Genauigkeit f√ºr Klasse 106: 0.00 %\n",
      "Genauigkeit f√ºr Klasse 107: 0.00 %\n",
      "Genauigkeit f√ºr Klasse 108: 0.00 %\n",
      "Genauigkeit f√ºr Klasse 109: 0.00 %\n",
      "\n",
      "Precision, Recall, F1-Score pro Klasse:\n",
      "Klasse 48: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 49: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 50: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 51: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 52: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 53: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 54: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 55: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 56: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 57: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 65: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 66: Precision=0.04, Recall=0.12, F1-Score=0.05\n",
      "Klasse 67: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 68: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 69: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 70: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 71: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 72: Precision=0.04, Recall=0.03, F1-Score=0.03\n",
      "Klasse 73: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 74: Precision=0.02, Recall=0.03, F1-Score=0.02\n",
      "Klasse 75: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 76: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 77: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 97: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 98: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 99: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 100: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 101: Precision=0.03, Recall=0.97, F1-Score=0.06\n",
      "Klasse 102: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 103: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 104: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 105: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 106: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 107: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 108: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 109: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "\n",
      "Durchschnittlicher F1-Score (gewichtet): 0.00\n",
      "\n",
      "Konfusionsmatrix:\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/timon/ML2Modularbeit/env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Durchschnittliche ROC-AUC: 0.53\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.172222222222222"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(model, test_loader, device, class_list):\n",
    "    model.eval()  # Setze das Modell in den Evaluierungsmodus\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():  # Keine Gradientenberechnung, da wir nur evaluieren\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        n_class_correct = defaultdict(int)\n",
    "        n_class_samples = defaultdict(int)\n",
    "\n",
    "        # Iteriere √ºber den Testdatensatz\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)  # Bilder auf das gleiche Ger√§t verschieben (GPU oder CPU)\n",
    "            labels = labels.to(device)  # Labels auf das gleiche Ger√§t verschieben (GPU oder CPU)\n",
    "            \n",
    "            # Vorw√§rtsdurchlauf\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Vorhersagen\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            # Update der Gesamtmetriken\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Update der Metriken pro Klasse\n",
    "            for i in range(labels.size(0)):\n",
    "                label = labels[i].item()\n",
    "                pred = predicted[i].item()\n",
    "                if label == pred:\n",
    "                    n_class_correct[label] += 1\n",
    "                n_class_samples[label] += 1\n",
    "\n",
    "            # Speichere alle Labels und Vorhersagen f√ºr die Berechnung der weiteren Metriken\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "        # Berechnung der Gesamtgenauigkeit\n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        print(f'Gesamtgenauigkeit des Netzwerks: {acc:.2f} %')\n",
    "\n",
    "        # Berechnung der Klasse-genauen Genauigkeit\n",
    "        for label in sorted(n_class_samples.keys()):\n",
    "            ascii_char = class_list[label]\n",
    "            class_acc = 100.0 * n_class_correct[label] / n_class_samples[label]\n",
    "            print(f'Genauigkeit f√ºr Klasse {ascii_char}: {class_acc:.2f} %')\n",
    "\n",
    "        # Berechnung der Precision, Recall und F1-Score f√ºr jede Klasse\n",
    "        precision = precision_score(all_labels, all_predictions, average=None, labels=np.unique(all_labels))\n",
    "        recall = recall_score(all_labels, all_predictions, average=None, labels=np.unique(all_labels))\n",
    "        f1 = f1_score(all_labels, all_predictions, average=None, labels=np.unique(all_labels))\n",
    "        \n",
    "        # Berechne den durchschnittlichen F1-Score\n",
    "        avg_f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "        \n",
    "        print(\"\\nPrecision, Recall, F1-Score pro Klasse:\")\n",
    "        for i, ascii_char in enumerate(class_list):\n",
    "            print(f\"Klasse {ascii_char}: Precision={precision[i]:.2f}, Recall={recall[i]:.2f}, F1-Score={f1[i]:.2f}\")\n",
    "        \n",
    "        print(f\"\\nDurchschnittlicher F1-Score (gewichtet): {avg_f1:.2f}\")\n",
    "\n",
    "        # Berechnung der Konfusionsmatrix\n",
    "        cm = confusion_matrix(all_labels, all_predictions)\n",
    "        print(f\"\\nKonfusionsmatrix:\\n{cm}\")\n",
    "\n",
    "        # Berechnung der ROC-AUC (f√ºr Multiklassen kann man dies auch f√ºr jedes Label einzeln berechnen)\n",
    "        try:\n",
    "            roc_auc = roc_auc_score(all_labels, model_output_to_probs(model, test_loader, device), multi_class='ovr', average='weighted')\n",
    "            print(f\"\\nDurchschnittliche ROC-AUC: {roc_auc:.2f}\")\n",
    "        except ValueError:\n",
    "            print(\"\\nROC-AUC konnte nicht berechnet werden (m√∂glicherweise nicht geeignet f√ºr das Problem).\")\n",
    "\n",
    "        return acc\n",
    "\n",
    "# Hilfsfunktion zur Berechnung der ROC-AUC f√ºr das Multiklassenproblem\n",
    "def model_output_to_probs(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    with torch.no_grad():\n",
    "        for images, _ in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    return np.array(all_probs)\n",
    "\n",
    "# Beispielaufruf\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # W√§hle GPU, wenn verf√ºgbar\n",
    "\n",
    "# Modell auf das Ger√§t (GPU/CPU) verschieben\n",
    "model = model.to(device)\n",
    "\n",
    "# Jetzt den Evaluierungscode aufrufen\n",
    "evaluate_model(model, test_loader, device, class_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e153ab6",
   "metadata": {},
   "source": [
    "# 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b2c2db",
   "metadata": {},
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d77fd76",
   "metadata": {},
   "source": [
    "list('0123456789ABCDEFGHIJKLMabcdefghijklm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fa0bb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_type_labeled_dataloaders(X_train, y_train, X_test, y_test, class_list, batch_size):\n",
    "    def get_type_labels(y_tensor):\n",
    "        type_labels = []\n",
    "        for label in y_tensor:\n",
    "            char = str(class_list[int(label)])  # Ensure it's a string\n",
    "            \n",
    "            if char.isdigit():\n",
    "                type_labels.append(0)  # Ziffer\n",
    "            elif char.isupper():\n",
    "                type_labels.append(1)  # Gro√übuchstabe\n",
    "            else:\n",
    "                type_labels.append(2)  # Kleinbuchstabe\n",
    "        return torch.tensor(type_labels, dtype=torch.long)\n",
    "\n",
    "    y_train_type = get_type_labels(y_train)\n",
    "    y_test_type = get_type_labels(y_test)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train, y_train, y_train_type)\n",
    "    test_dataset = TensorDataset(X_test, y_test, y_test_type)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611a1553",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "605e97f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = create_type_labeled_dataloaders(\n",
    "    X_train, y_train, X_test, y_test,\n",
    "    class_list=class_list,\n",
    "    batch_size=best_params[\"batch_size\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a43519a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a1ade3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type_label_tensor(label_tensor):\n",
    "    class_list = list('0123456789ABCDEFGHIJKLMabcdefghijklm')\n",
    "    label_to_class = {i: c for i, c in enumerate(class_list)}\n",
    "    \n",
    "    type_labels = []\n",
    "    for label in label_tensor:\n",
    "        char = label_to_class[int(label)]\n",
    "        if char.isdigit():\n",
    "            type_labels.append(0)\n",
    "        elif char.isupper():\n",
    "            type_labels.append(1)\n",
    "        else:\n",
    "            type_labels.append(2)\n",
    "    return torch.tensor(type_labels, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9fa091c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_type = get_type_label_tensor(y_train)\n",
    "y_test_type = get_type_label_tensor(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "391d2ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train, y_train, y_train_type)\n",
    "test_dataset = TensorDataset(X_test, y_test, y_test_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c8f7f98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispielhafte Klasse-zu-Typ-Zuordnung: 0 = Gro√ü, 1 = Klein, 2 = Ziffer\n",
    "def get_type_label_tensor(y):\n",
    "    type_labels = []\n",
    "    for label in y:\n",
    "        char = class_list[label]\n",
    "        if char.isdigit():\n",
    "            type_labels.append(2)\n",
    "        elif char.isupper():\n",
    "            type_labels.append(0)\n",
    "        else:\n",
    "            type_labels.append(1)\n",
    "    return torch.tensor(type_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbcbbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0d475d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TypeClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TypeClassifier, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 7 * 7, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return F.softmax(self.fc(x), dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1da19808",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModularClassifier(nn.Module):\n",
    "    def __init__(self, tm1, tm2, class_type_map):\n",
    "        super(ModularClassifier, self).__init__()\n",
    "        self.tm1 = tm1\n",
    "        self.tm2 = tm2\n",
    "        self.class_type_map = torch.tensor(class_type_map, dtype=torch.long)  # L√§nge 36\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_cls = self.tm1(x)  # shape (B, 36)\n",
    "        out_type = self.tm2(x)  # shape (B, 3)\n",
    "\n",
    "        type_probs = out_type[:, self.class_type_map.to(x.device)]  # shape (B, 36)\n",
    "        final_out = out_cls * type_probs  # Elementweise Multiplikation\n",
    "\n",
    "        return final_out, out_cls, out_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8ff7ec0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'isdigit'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m class_type_map = []\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m class_list:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mc\u001b[49m\u001b[43m.\u001b[49m\u001b[43misdigit\u001b[49m():\n\u001b[32m      5\u001b[39m         class_type_map.append(\u001b[32m2\u001b[39m)\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m c.isupper():\n",
      "\u001b[31mAttributeError\u001b[39m: 'int' object has no attribute 'isdigit'"
     ]
    }
   ],
   "source": [
    "# class_list = ['0', '1', ..., 'a', 'b', ...]\n",
    "class_type_map = []\n",
    "for c in class_list:\n",
    "    if c.isdigit():\n",
    "        class_type_map.append(2)\n",
    "    elif c.isupper():\n",
    "        class_type_map.append(0)\n",
    "    else:\n",
    "        class_type_map.append(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "567bee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tm1 = ResNet18(num_classes=len(class_list))\n",
    "\n",
    "modular_model = ModularClassifier(\n",
    "    tm1,\n",
    "    tm2=TypeClassifier(),\n",
    "    class_type_map=class_type_map\n",
    ").to(device)\n",
    "\n",
    "criterion_cls = nn.CrossEntropyLoss()\n",
    "criterion_type = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(modular_model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ce4c6de",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (36) must match the size of tensor b (0) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m labels_cls = labels_cls.to(device)\n\u001b[32m      8\u001b[39m labels_type = labels_type.to(device)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m final_out, out_cls, out_type = \u001b[43mmodular_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m loss_cls = criterion_cls(out_cls, labels_cls)\n\u001b[32m     13\u001b[39m loss_type = criterion_type(out_type, labels_type)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ML2Modularbeit/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ML2Modularbeit/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mModularClassifier.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     10\u001b[39m out_type = \u001b[38;5;28mself\u001b[39m.tm2(x)  \u001b[38;5;66;03m# shape (B, 3)\u001b[39;00m\n\u001b[32m     12\u001b[39m type_probs = out_type[:, \u001b[38;5;28mself\u001b[39m.class_type_map.to(x.device)]  \u001b[38;5;66;03m# shape (B, 36)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m final_out = \u001b[43mout_cls\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_probs\u001b[49m  \u001b[38;5;66;03m# Elementweise Multiplikation\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m final_out, out_cls, out_type\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (36) must match the size of tensor b (0) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    modular_model.train()\n",
    "    total_loss = 0.0  # ‚úÖ richtig initialisieren\n",
    "\n",
    "    for images, labels_cls, labels_type in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels_cls = labels_cls.to(device)\n",
    "        labels_type = labels_type.to(device)\n",
    "\n",
    "        final_out, out_cls, out_type = modular_model(images)\n",
    "\n",
    "        loss_cls = criterion_cls(out_cls, labels_cls)\n",
    "        loss_type = criterion_type(out_type, labels_type)\n",
    "        loss = loss_cls + 0.5 * loss_type\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()  # ‚úÖ jetzt ist total_loss eine float\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e2e7ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8fdf48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
