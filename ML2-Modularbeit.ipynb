{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8168e98c",
   "metadata": {},
   "source": [
    "# Timon Spichtinger Machine Learning 2 Modularbeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "113ca418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import EMNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch\n",
    "import importlib\n",
    "\n",
    "\n",
    "from Datensatz import get_emnist_test_train, show_random_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3bf0cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9b5f04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ziel-ASCII: [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109]\n",
      "Anzahl Zielklassen: 36\n",
      "⚠️ Klasse B: nur 3878 echte Bilder – augmentiere 2122 zusätzlich.\n",
      "⚠️ Klasse D: nur 4562 echte Bilder – augmentiere 1438 zusätzlich.\n",
      "⚠️ Klasse E: nur 4934 echte Bilder – augmentiere 1066 zusätzlich.\n",
      "⚠️ Klasse G: nur 2517 echte Bilder – augmentiere 3483 zusätzlich.\n",
      "⚠️ Klasse H: nur 3152 echte Bilder – augmentiere 2848 zusätzlich.\n",
      "⚠️ Klasse J: nur 3762 echte Bilder – augmentiere 2238 zusätzlich.\n",
      "⚠️ Klasse K: nur 2468 echte Bilder – augmentiere 3532 zusätzlich.\n",
      "⚠️ Klasse L: nur 5076 echte Bilder – augmentiere 924 zusätzlich.\n",
      "⚠️ Klasse b: nur 5159 echte Bilder – augmentiere 841 zusätzlich.\n",
      "⚠️ Klasse c: nur 2854 echte Bilder – augmentiere 3146 zusätzlich.\n",
      "⚠️ Klasse f: nur 2561 echte Bilder – augmentiere 3439 zusätzlich.\n",
      "⚠️ Klasse g: nur 3687 echte Bilder – augmentiere 2313 zusätzlich.\n",
      "⚠️ Klasse i: nur 2725 echte Bilder – augmentiere 3275 zusätzlich.\n",
      "⚠️ Klasse j: nur 1896 echte Bilder – augmentiere 4104 zusätzlich.\n",
      "⚠️ Klasse k: nur 2491 echte Bilder – augmentiere 3509 zusätzlich.\n",
      "⚠️ Klasse m: nur 2645 echte Bilder – augmentiere 3355 zusätzlich.\n",
      "✅ Trainingsdaten: torch.Size([180000, 1, 28, 28]) torch.Size([180000])\n",
      "✅ Testdaten: torch.Size([36000, 1, 28, 28]) torch.Size([36000])\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test,classlist = get_emnist_test_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39fe5cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x200 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "show_random_samples(X_test, y_test, classlist, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "295aecc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in ./env/lib/python3.12/site-packages (4.3.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in ./env/lib/python3.12/site-packages (from optuna) (1.16.1)\n",
      "Requirement already satisfied: colorlog in ./env/lib/python3.12/site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in ./env/lib/python3.12/site-packages (from optuna) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in ./env/lib/python3.12/site-packages (from optuna) (25.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in ./env/lib/python3.12/site-packages (from optuna) (2.0.41)\n",
      "Requirement already satisfied: tqdm in ./env/lib/python3.12/site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in ./env/lib/python3.12/site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: Mako in ./env/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in ./env/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (4.14.0)\n",
      "Requirement already satisfied: greenlet>=1 in ./env/lib/python3.12/site-packages (from sqlalchemy>=1.4.2->optuna) (3.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in ./env/lib/python3.12/site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c18fcdfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-05 17:32:19,725] A new study created in memory with name: no-name-460049ad-57c2-4ed4-9ce1-0fa7cd32de13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-05 17:35:54,069] Trial 0 finished with value: 0.8629166666666667 and parameters: {'batch_size': 144, 'lr': 0.014698316807089204, 'momentum': 0.874277340260224, 'step_size': 5, 'gamma': 0.6768723939016551}. Best is trial 0 with value: 0.8629166666666667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-05 17:38:53,507] Trial 1 finished with value: 0.8325555555555556 and parameters: {'batch_size': 256, 'lr': 0.00033424219531098814, 'momentum': 0.7643542955806851, 'step_size': 5, 'gamma': 0.9246937106893565}. Best is trial 0 with value: 0.8629166666666667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-05 17:45:03,906] Trial 2 finished with value: 0.8496111111111111 and parameters: {'batch_size': 64, 'lr': 0.00022516734429942244, 'momentum': 0.9333259096785842, 'step_size': 5, 'gamma': 0.6112409725732096}. Best is trial 0 with value: 0.8629166666666667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-05 17:47:39,258] Trial 3 finished with value: 0.84525 and parameters: {'batch_size': 144, 'lr': 0.0004143857091349456, 'momentum': 0.9102771947508954, 'step_size': 5, 'gamma': 0.9407238232263457}. Best is trial 0 with value: 0.8629166666666667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-05 17:50:22,849] Trial 4 finished with value: 0.8572222222222222 and parameters: {'batch_size': 256, 'lr': 0.023123259668382204, 'momentum': 0.6213043963938398, 'step_size': 4, 'gamma': 0.7042600545097379}. Best is trial 0 with value: 0.8629166666666667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-05 17:54:14,029] Trial 5 finished with value: 0.8373055555555555 and parameters: {'batch_size': 144, 'lr': 0.00026441074752157743, 'momentum': 0.7267296291605531, 'step_size': 2, 'gamma': 0.9334353408364608}. Best is trial 0 with value: 0.8629166666666667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-05 17:56:27,572] Trial 6 finished with value: 0.8665 and parameters: {'batch_size': 256, 'lr': 0.0205488561048036, 'momentum': 0.9319936071772215, 'step_size': 4, 'gamma': 0.663470904631867}. Best is trial 6 with value: 0.8665.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-05 18:00:56,244] Trial 7 finished with value: 0.8338055555555556 and parameters: {'batch_size': 256, 'lr': 0.00013669687199750844, 'momentum': 0.8780580084516649, 'step_size': 4, 'gamma': 0.5939890075296753}. Best is trial 6 with value: 0.8665.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-05 18:03:30,112] Trial 8 finished with value: 0.8554444444444445 and parameters: {'batch_size': 144, 'lr': 0.0031731181463308124, 'momentum': 0.6149502380602546, 'step_size': 2, 'gamma': 0.6618571521360993}. Best is trial 6 with value: 0.8665.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-05 18:05:59,653] Trial 9 finished with value: 0.8608055555555556 and parameters: {'batch_size': 256, 'lr': 0.015284553379410242, 'momentum': 0.902892311649933, 'step_size': 5, 'gamma': 0.5951097285446874}. Best is trial 6 with value: 0.8665.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-05 18:10:00,138] Trial 10 finished with value: 0.8697777777777778 and parameters: {'batch_size': 128, 'lr': 0.08883951844729966, 'momentum': 0.8236279947277043, 'step_size': 3, 'gamma': 0.5062463512070597}. Best is trial 10 with value: 0.8697777777777778.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-05 18:13:40,547] Trial 11 finished with value: 0.8703888888888889 and parameters: {'batch_size': 128, 'lr': 0.09372982446705289, 'momentum': 0.808644091972167, 'step_size': 3, 'gamma': 0.50889620710297}. Best is trial 11 with value: 0.8703888888888889.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-05 18:17:20,922] Trial 12 finished with value: 0.8696944444444444 and parameters: {'batch_size': 128, 'lr': 0.08452263650308278, 'momentum': 0.82117699619067, 'step_size': 3, 'gamma': 0.5140607691017608}. Best is trial 11 with value: 0.8703888888888889.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-05 18:20:59,301] Trial 13 finished with value: 0.8707777777777778 and parameters: {'batch_size': 128, 'lr': 0.09348522521531417, 'momentum': 0.823902807903623, 'step_size': 3, 'gamma': 0.5136881005205461}. Best is trial 13 with value: 0.8707777777777778.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-05 18:23:40,190] Trial 14 finished with value: 0.8551666666666666 and parameters: {'batch_size': 128, 'lr': 0.0033766102454530003, 'momentum': 0.698904247064388, 'step_size': 3, 'gamma': 0.7800041605620166}. Best is trial 13 with value: 0.8707777777777778.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-05 18:27:39,863] Trial 15 finished with value: 0.8666944444444444 and parameters: {'batch_size': 128, 'lr': 0.04347779766355281, 'momentum': 0.826074572643684, 'step_size': 3, 'gamma': 0.802078374212669}. Best is trial 13 with value: 0.8707777777777778.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-05 18:30:39,743] Trial 16 finished with value: 0.8521944444444445 and parameters: {'batch_size': 128, 'lr': 0.0010869905897972038, 'momentum': 0.7865640769874449, 'step_size': 2, 'gamma': 0.5594259863174312}. Best is trial 13 with value: 0.8707777777777778.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-05 18:36:11,418] Trial 17 finished with value: 0.8666111111111111 and parameters: {'batch_size': 64, 'lr': 0.006401049717521514, 'momentum': 0.6931752013101573, 'step_size': 3, 'gamma': 0.5474573835684986}. Best is trial 13 with value: 0.8707777777777778.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-05 18:38:52,885] Trial 18 finished with value: 0.8545833333333334 and parameters: {'batch_size': 128, 'lr': 0.04160307021784333, 'momentum': 0.7829560907843005, 'step_size': 4, 'gamma': 0.7715540372701509}. Best is trial 13 with value: 0.8707777777777778.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-05 18:41:12,980] Trial 19 finished with value: 0.8533055555555555 and parameters: {'batch_size': 128, 'lr': 0.0013526640851865795, 'momentum': 0.8534965150496183, 'step_size': 2, 'gamma': 0.877759386718596}. Best is trial 13 with value: 0.8707777777777778.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Beste Hyperparameter:\n",
      "batch_size: 128\n",
      "lr: 0.09348522521531417\n",
      "momentum: 0.823902807903623\n",
      "step_size: 3\n",
      "gamma: 0.5136881005205461\n",
      "🔁 Epoch 1, Step 200/1407: Batch Loss = 0.7476\n",
      "🔁 Epoch 1, Step 400/1407: Batch Loss = 0.7168\n",
      "🔁 Epoch 1, Step 600/1407: Batch Loss = 0.4487\n",
      "🔁 Epoch 1, Step 800/1407: Batch Loss = 0.5777\n",
      "🔁 Epoch 1, Step 1000/1407: Batch Loss = 0.3855\n",
      "🔁 Epoch 1, Step 1200/1407: Batch Loss = 0.3975\n",
      "🔁 Epoch 1, Step 1400/1407: Batch Loss = 0.3404\n",
      "📊 Epoch 1: Train Acc = 77.29%, Val Acc = 83.00%, Val Loss = 0.4252, LR = [0.09348522521531417]\n",
      "🔁 Epoch 2, Step 200/1407: Batch Loss = 0.3754\n",
      "🔁 Epoch 2, Step 400/1407: Batch Loss = 0.4212\n",
      "🔁 Epoch 2, Step 600/1407: Batch Loss = 0.3830\n",
      "🔁 Epoch 2, Step 800/1407: Batch Loss = 0.3210\n",
      "🔁 Epoch 2, Step 1000/1407: Batch Loss = 0.2682\n",
      "🔁 Epoch 2, Step 1200/1407: Batch Loss = 0.3850\n",
      "🔁 Epoch 2, Step 1400/1407: Batch Loss = 0.5214\n",
      "📊 Epoch 2: Train Acc = 83.97%, Val Acc = 83.75%, Val Loss = 0.4145, LR = [0.09348522521531417]\n",
      "🔁 Epoch 3, Step 200/1407: Batch Loss = 0.4803\n",
      "🔁 Epoch 3, Step 400/1407: Batch Loss = 0.4028\n",
      "🔁 Epoch 3, Step 600/1407: Batch Loss = 0.4163\n",
      "🔁 Epoch 3, Step 800/1407: Batch Loss = 0.3441\n",
      "🔁 Epoch 3, Step 1000/1407: Batch Loss = 0.2632\n",
      "🔁 Epoch 3, Step 1200/1407: Batch Loss = 0.4494\n",
      "🔁 Epoch 3, Step 1400/1407: Batch Loss = 0.2563\n",
      "📊 Epoch 3: Train Acc = 85.27%, Val Acc = 84.80%, Val Loss = 0.3761, LR = [0.048022247767590204]\n",
      "🔁 Epoch 4, Step 200/1407: Batch Loss = 0.3666\n",
      "🔁 Epoch 4, Step 400/1407: Batch Loss = 0.2903\n",
      "🔁 Epoch 4, Step 600/1407: Batch Loss = 0.3387\n",
      "🔁 Epoch 4, Step 800/1407: Batch Loss = 0.3230\n",
      "🔁 Epoch 4, Step 1000/1407: Batch Loss = 0.3397\n",
      "🔁 Epoch 4, Step 1200/1407: Batch Loss = 0.3341\n",
      "🔁 Epoch 4, Step 1400/1407: Batch Loss = 0.3897\n",
      "📊 Epoch 4: Train Acc = 87.00%, Val Acc = 86.31%, Val Loss = 0.3362, LR = [0.048022247767590204]\n",
      "🔁 Epoch 5, Step 200/1407: Batch Loss = 0.3542\n",
      "🔁 Epoch 5, Step 400/1407: Batch Loss = 0.2638\n",
      "🔁 Epoch 5, Step 600/1407: Batch Loss = 0.2821\n",
      "🔁 Epoch 5, Step 800/1407: Batch Loss = 0.3521\n",
      "🔁 Epoch 5, Step 1000/1407: Batch Loss = 0.2946\n",
      "🔁 Epoch 5, Step 1200/1407: Batch Loss = 0.2908\n",
      "🔁 Epoch 5, Step 1400/1407: Batch Loss = 0.2856\n",
      "📊 Epoch 5: Train Acc = 87.47%, Val Acc = 86.65%, Val Loss = 0.3311, LR = [0.048022247767590204]\n",
      "🔁 Epoch 6, Step 200/1407: Batch Loss = 0.2766\n",
      "🔁 Epoch 6, Step 400/1407: Batch Loss = 0.3570\n",
      "🔁 Epoch 6, Step 600/1407: Batch Loss = 0.3236\n",
      "🔁 Epoch 6, Step 800/1407: Batch Loss = 0.3314\n",
      "🔁 Epoch 6, Step 1000/1407: Batch Loss = 0.2356\n",
      "🔁 Epoch 6, Step 1200/1407: Batch Loss = 0.3280\n",
      "🔁 Epoch 6, Step 1400/1407: Batch Loss = 0.3039\n",
      "📊 Epoch 6: Train Acc = 87.74%, Val Acc = 86.62%, Val Loss = 0.3307, LR = [0.02466845723846045]\n",
      "🔁 Epoch 7, Step 200/1407: Batch Loss = 0.2611\n",
      "🔁 Epoch 7, Step 400/1407: Batch Loss = 0.2273\n",
      "🔁 Epoch 7, Step 600/1407: Batch Loss = 0.2603\n",
      "🔁 Epoch 7, Step 800/1407: Batch Loss = 0.2583\n",
      "🔁 Epoch 7, Step 1000/1407: Batch Loss = 0.1939\n",
      "🔁 Epoch 7, Step 1200/1407: Batch Loss = 0.2227\n",
      "🔁 Epoch 7, Step 1400/1407: Batch Loss = 0.2906\n",
      "📊 Epoch 7: Train Acc = 88.69%, Val Acc = 87.24%, Val Loss = 0.3204, LR = [0.02466845723846045]\n",
      "🔁 Epoch 8, Step 200/1407: Batch Loss = 0.2731\n",
      "🔁 Epoch 8, Step 400/1407: Batch Loss = 0.1960\n",
      "🔁 Epoch 8, Step 600/1407: Batch Loss = 0.3105\n",
      "🔁 Epoch 8, Step 800/1407: Batch Loss = 0.1847\n",
      "🔁 Epoch 8, Step 1000/1407: Batch Loss = 0.3089\n",
      "🔁 Epoch 8, Step 1200/1407: Batch Loss = 0.3498\n",
      "🔁 Epoch 8, Step 1400/1407: Batch Loss = 0.2824\n",
      "📊 Epoch 8: Train Acc = 89.08%, Val Acc = 86.96%, Val Loss = 0.3278, LR = [0.02466845723846045]\n",
      "🔁 Epoch 9, Step 200/1407: Batch Loss = 0.1883\n",
      "🔁 Epoch 9, Step 400/1407: Batch Loss = 0.1877\n",
      "🔁 Epoch 9, Step 600/1407: Batch Loss = 0.3811\n",
      "🔁 Epoch 9, Step 800/1407: Batch Loss = 0.2465\n",
      "🔁 Epoch 9, Step 1000/1407: Batch Loss = 0.2171\n",
      "🔁 Epoch 9, Step 1200/1407: Batch Loss = 0.2923\n",
      "🔁 Epoch 9, Step 1400/1407: Batch Loss = 0.1961\n",
      "📊 Epoch 9: Train Acc = 89.36%, Val Acc = 87.09%, Val Loss = 0.3292, LR = [0.012671892941597067]\n",
      "🔁 Epoch 10, Step 200/1407: Batch Loss = 0.3393\n",
      "🔁 Epoch 10, Step 400/1407: Batch Loss = 0.1689\n",
      "🔁 Epoch 10, Step 600/1407: Batch Loss = 0.2357\n",
      "🔁 Epoch 10, Step 800/1407: Batch Loss = 0.1776\n",
      "🔁 Epoch 10, Step 1000/1407: Batch Loss = 0.2570\n",
      "🔁 Epoch 10, Step 1200/1407: Batch Loss = 0.2032\n",
      "🔁 Epoch 10, Step 1400/1407: Batch Loss = 0.2060\n",
      "📊 Epoch 10: Train Acc = 90.04%, Val Acc = 87.19%, Val Loss = 0.3305, LR = [0.012671892941597067]\n",
      "🔁 Epoch 11, Step 200/1407: Batch Loss = 0.1971\n",
      "🔁 Epoch 11, Step 400/1407: Batch Loss = 0.2243\n",
      "🔁 Epoch 11, Step 600/1407: Batch Loss = 0.2725\n",
      "🔁 Epoch 11, Step 800/1407: Batch Loss = 0.2501\n",
      "🔁 Epoch 11, Step 1000/1407: Batch Loss = 0.2159\n",
      "🔁 Epoch 11, Step 1200/1407: Batch Loss = 0.1892\n",
      "🔁 Epoch 11, Step 1400/1407: Batch Loss = 0.2142\n",
      "📊 Epoch 11: Train Acc = 90.28%, Val Acc = 87.21%, Val Loss = 0.3325, LR = [0.012671892941597067]\n",
      "🛑 Early stopping ausgelöst bei Epoch 11 (Val Loss: 0.3325)\n",
      "✅ Modell gespeichert.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import transforms\n",
    "from collections import defaultdict\n",
    "import optuna\n",
    "from Klassifikator import ResNet18  # oder AlexNet, GoogLeNet\n",
    "\n",
    "# Gerät\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Klassenliste (36 Klassen)\n",
    "class_list = list('0123456789ABCDEFGHIJKLMabcdefghijklm')\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Early Stopping\n",
    "# -----------------------------\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=4, min_delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None or val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Optuna-Ziel-Funktion\n",
    "# -----------------------------\n",
    "def objective(trial):\n",
    "    # Hyperparameter-Sampling\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [64, 128, 144, 256])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 0.1, log=True)\n",
    "    momentum = trial.suggest_float(\"momentum\", 0.6, 0.95)\n",
    "    step_size = trial.suggest_int(\"step_size\", 2, 5)\n",
    "    gamma = trial.suggest_float(\"gamma\", 0.5, 0.95)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = ResNet18(num_classes=len(class_list)).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=4)\n",
    "\n",
    "    for epoch in range(20):  # ggf. mehr bei finalem Training\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # Validierungs-Loss berechnen\n",
    "        val_loss = 0.0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                val_loss += criterion(outputs, labels).item()\n",
    "        val_loss /= len(test_loader)\n",
    "\n",
    "        early_stopping(val_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"⛔ Early Stopping in Epoch {epoch+1}\")\n",
    "            break\n",
    "        print(f\"📉 Epoch {epoch+1}: Val Loss = {val_loss:.4f}\")\n",
    "\n",
    "\n",
    "    # Genauigkeit auf Testdaten\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Optuna-Studie starten\n",
    "# -----------------------------\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# Beste Parameter anzeigen\n",
    "print(\"🎯 Beste Hyperparameter:\")\n",
    "for k, v in study.best_params.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Finales Training mit besten Parametern (optional)\n",
    "# -----------------------------\n",
    "best_params = study.best_params\n",
    "train_loader = DataLoader(train_dataset, batch_size=best_params[\"batch_size\"], shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=best_params[\"batch_size\"], shuffle=False)\n",
    "\n",
    "model = ResNet18(num_classes=len(class_list)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=best_params[\"lr\"], momentum=best_params[\"momentum\"])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=best_params[\"step_size\"], gamma=best_params[\"gamma\"])\n",
    "early_stopping = EarlyStopping(patience=4)\n",
    "\n",
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        if (i + 1) % 200 == 0:\n",
    "            print(f\"🔁 Epoch {epoch+1}, Step {i+1}/{len(train_loader)}: Batch Loss = {loss.item():.4f}\")\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # Validierung\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "    val_loss /= len(test_loader)\n",
    "    train_acc = 100.0 * correct_train / total_train\n",
    "    val_acc = 100.0 * correct_val / total_val\n",
    "\n",
    "    print(f\"📊 Epoch {epoch+1}: Train Acc = {train_acc:.2f}%, Val Acc = {val_acc:.2f}%, Val Loss = {val_loss:.4f}, LR = {scheduler.get_last_lr()}\")\n",
    "\n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(f\"🛑 Early stopping ausgelöst bei Epoch {epoch+1} (Val Loss: {val_loss:.4f})\")\n",
    "        break\n",
    "\n",
    "# Modell speichern\n",
    "torch.save(model.state_dict(), './resnet18_best_hyperparams.pth')\n",
    "print(\"✅ Modell gespeichert.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4baf65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gesamtgenauigkeit des Netzwerks: 87.21 %\n",
      "Genauigkeit für Klasse 0: 95.80 %\n",
      "Genauigkeit für Klasse 1: 64.40 %\n",
      "Genauigkeit für Klasse 2: 98.90 %\n",
      "Genauigkeit für Klasse 3: 99.10 %\n",
      "Genauigkeit für Klasse 4: 99.20 %\n",
      "Genauigkeit für Klasse 5: 98.50 %\n",
      "Genauigkeit für Klasse 6: 95.00 %\n",
      "Genauigkeit für Klasse 7: 99.30 %\n",
      "Genauigkeit für Klasse 8: 98.40 %\n",
      "Genauigkeit für Klasse 9: 95.00 %\n",
      "Genauigkeit für Klasse A: 99.00 %\n",
      "Genauigkeit für Klasse B: 97.30 %\n",
      "Genauigkeit für Klasse C: 83.60 %\n",
      "Genauigkeit für Klasse D: 95.30 %\n",
      "Genauigkeit für Klasse E: 97.30 %\n",
      "Genauigkeit für Klasse F: 81.40 %\n",
      "Genauigkeit für Klasse G: 94.60 %\n",
      "Genauigkeit für Klasse H: 97.50 %\n",
      "Genauigkeit für Klasse I: 64.70 %\n",
      "Genauigkeit für Klasse J: 87.60 %\n",
      "Genauigkeit für Klasse K: 79.60 %\n",
      "Genauigkeit für Klasse L: 95.20 %\n",
      "Genauigkeit für Klasse M: 92.50 %\n",
      "Genauigkeit für Klasse a: 94.90 %\n",
      "Genauigkeit für Klasse b: 92.00 %\n",
      "Genauigkeit für Klasse c: 69.60 %\n",
      "Genauigkeit für Klasse d: 98.30 %\n",
      "Genauigkeit für Klasse e: 97.30 %\n",
      "Genauigkeit für Klasse f: 75.00 %\n",
      "Genauigkeit für Klasse g: 79.50 %\n",
      "Genauigkeit für Klasse h: 96.60 %\n",
      "Genauigkeit für Klasse i: 72.80 %\n",
      "Genauigkeit für Klasse j: 78.40 %\n",
      "Genauigkeit für Klasse k: 64.20 %\n",
      "Genauigkeit für Klasse l: 44.70 %\n",
      "Genauigkeit für Klasse m: 66.90 %\n",
      "\n",
      "Precision, Recall, F1-Score pro Klasse:\n",
      "Klasse 0: Precision=0.97, Recall=0.96, F1-Score=0.96\n",
      "Klasse 1: Precision=0.53, Recall=0.64, F1-Score=0.58\n",
      "Klasse 2: Precision=0.99, Recall=0.99, F1-Score=0.99\n",
      "Klasse 3: Precision=0.99, Recall=0.99, F1-Score=0.99\n",
      "Klasse 4: Precision=0.99, Recall=0.99, F1-Score=0.99\n",
      "Klasse 5: Precision=0.99, Recall=0.98, F1-Score=0.99\n",
      "Klasse 6: Precision=0.95, Recall=0.95, F1-Score=0.95\n",
      "Klasse 7: Precision=0.99, Recall=0.99, F1-Score=0.99\n",
      "Klasse 8: Precision=0.98, Recall=0.98, F1-Score=0.98\n",
      "Klasse 9: Precision=0.89, Recall=0.95, F1-Score=0.92\n",
      "Klasse A: Precision=0.97, Recall=0.99, F1-Score=0.98\n",
      "Klasse B: Precision=0.96, Recall=0.97, F1-Score=0.96\n",
      "Klasse C: Precision=0.74, Recall=0.84, F1-Score=0.78\n",
      "Klasse D: Precision=0.94, Recall=0.95, F1-Score=0.95\n",
      "Klasse E: Precision=0.98, Recall=0.97, F1-Score=0.97\n",
      "Klasse F: Precision=0.78, Recall=0.81, F1-Score=0.80\n",
      "Klasse G: Precision=0.93, Recall=0.95, F1-Score=0.94\n",
      "Klasse H: Precision=0.96, Recall=0.97, F1-Score=0.97\n",
      "Klasse I: Precision=0.58, Recall=0.65, F1-Score=0.61\n",
      "Klasse J: Precision=0.86, Recall=0.88, F1-Score=0.87\n",
      "Klasse K: Precision=0.70, Recall=0.80, F1-Score=0.75\n",
      "Klasse L: Precision=0.93, Recall=0.95, F1-Score=0.94\n",
      "Klasse M: Precision=0.74, Recall=0.93, F1-Score=0.82\n",
      "Klasse a: Precision=0.95, Recall=0.95, F1-Score=0.95\n",
      "Klasse b: Precision=0.94, Recall=0.92, F1-Score=0.93\n",
      "Klasse c: Precision=0.79, Recall=0.70, F1-Score=0.74\n",
      "Klasse d: Precision=0.98, Recall=0.98, F1-Score=0.98\n",
      "Klasse e: Precision=0.98, Recall=0.97, F1-Score=0.98\n",
      "Klasse f: Precision=0.78, Recall=0.75, F1-Score=0.77\n",
      "Klasse g: Precision=0.90, Recall=0.80, F1-Score=0.84\n",
      "Klasse h: Precision=0.98, Recall=0.97, F1-Score=0.97\n",
      "Klasse i: Precision=0.82, Recall=0.73, F1-Score=0.77\n",
      "Klasse j: Precision=0.82, Recall=0.78, F1-Score=0.80\n",
      "Klasse k: Precision=0.74, Recall=0.64, F1-Score=0.69\n",
      "Klasse l: Precision=0.56, Recall=0.45, F1-Score=0.50\n",
      "Klasse m: Precision=0.90, Recall=0.67, F1-Score=0.77\n",
      "\n",
      "Durchschnittlicher F1-Score (gewichtet): 0.87\n",
      "\n",
      "Konfusionsmatrix:\n",
      "[[958   0   0 ...   0   0   0]\n",
      " [  0 644   0 ...   0 196   0]\n",
      " [  0   0 989 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ... 642   0   0]\n",
      " [  0 321   0 ...   0 447   0]\n",
      " [  0   0   0 ...   2   0 669]]\n",
      "\n",
      "Durchschnittliche ROC-AUC: 1.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "87.20555555555555"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(model, test_loader, device, class_list):\n",
    "    model.eval()  # Setze das Modell in den Evaluierungsmodus\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():  # Keine Gradientenberechnung, da wir nur evaluieren\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        n_class_correct = defaultdict(int)\n",
    "        n_class_samples = defaultdict(int)\n",
    "\n",
    "        # Iteriere über den Testdatensatz\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)  # Bilder auf das gleiche Gerät verschieben (GPU oder CPU)\n",
    "            labels = labels.to(device)  # Labels auf das gleiche Gerät verschieben (GPU oder CPU)\n",
    "            \n",
    "            # Vorwärtsdurchlauf\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Vorhersagen\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            # Update der Gesamtmetriken\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Update der Metriken pro Klasse\n",
    "            for i in range(labels.size(0)):\n",
    "                label = labels[i].item()\n",
    "                pred = predicted[i].item()\n",
    "                if label == pred:\n",
    "                    n_class_correct[label] += 1\n",
    "                n_class_samples[label] += 1\n",
    "\n",
    "            # Speichere alle Labels und Vorhersagen für die Berechnung der weiteren Metriken\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "        # Berechnung der Gesamtgenauigkeit\n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        print(f'Gesamtgenauigkeit des Netzwerks: {acc:.2f} %')\n",
    "\n",
    "        # Berechnung der Klasse-genauen Genauigkeit\n",
    "        for label in sorted(n_class_samples.keys()):\n",
    "            ascii_char = class_list[label]\n",
    "            class_acc = 100.0 * n_class_correct[label] / n_class_samples[label]\n",
    "            print(f'Genauigkeit für Klasse {ascii_char}: {class_acc:.2f} %')\n",
    "\n",
    "        # Berechnung der Precision, Recall und F1-Score für jede Klasse\n",
    "        precision = precision_score(all_labels, all_predictions, average=None, labels=np.unique(all_labels))\n",
    "        recall = recall_score(all_labels, all_predictions, average=None, labels=np.unique(all_labels))\n",
    "        f1 = f1_score(all_labels, all_predictions, average=None, labels=np.unique(all_labels))\n",
    "        \n",
    "        # Berechne den durchschnittlichen F1-Score\n",
    "        avg_f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "        \n",
    "        print(\"\\nPrecision, Recall, F1-Score pro Klasse:\")\n",
    "        for i, ascii_char in enumerate(class_list):\n",
    "            print(f\"Klasse {ascii_char}: Precision={precision[i]:.2f}, Recall={recall[i]:.2f}, F1-Score={f1[i]:.2f}\")\n",
    "        \n",
    "        print(f\"\\nDurchschnittlicher F1-Score (gewichtet): {avg_f1:.2f}\")\n",
    "\n",
    "        # Berechnung der Konfusionsmatrix\n",
    "        cm = confusion_matrix(all_labels, all_predictions)\n",
    "        print(f\"\\nKonfusionsmatrix:\\n{cm}\")\n",
    "\n",
    "        # Berechnung der ROC-AUC (für Multiklassen kann man dies auch für jedes Label einzeln berechnen)\n",
    "        try:\n",
    "            roc_auc = roc_auc_score(all_labels, model_output_to_probs(model, test_loader, device), multi_class='ovr', average='weighted')\n",
    "            print(f\"\\nDurchschnittliche ROC-AUC: {roc_auc:.2f}\")\n",
    "        except ValueError:\n",
    "            print(\"\\nROC-AUC konnte nicht berechnet werden (möglicherweise nicht geeignet für das Problem).\")\n",
    "\n",
    "        return acc\n",
    "\n",
    "# Hilfsfunktion zur Berechnung der ROC-AUC für das Multiklassenproblem\n",
    "def model_output_to_probs(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    with torch.no_grad():\n",
    "        for images, _ in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    return np.array(all_probs)\n",
    "\n",
    "# Beispielaufruf\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # Wähle GPU, wenn verfügbar\n",
    "\n",
    "# Modell auf das Gerät (GPU/CPU) verschieben\n",
    "model = model.to(device)\n",
    "\n",
    "# Jetzt den Evaluierungscode aufrufen\n",
    "evaluate_model(model, test_loader, device, class_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcbcbbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gesamtgenauigkeit des Netzwerks: 87.21 %\n",
      "Genauigkeit für Klasse 0: 95.80 %\n",
      "Genauigkeit für Klasse 1: 64.40 %\n",
      "Genauigkeit für Klasse 2: 98.90 %\n",
      "Genauigkeit für Klasse 3: 99.10 %\n",
      "Genauigkeit für Klasse 4: 99.20 %\n",
      "Genauigkeit für Klasse 5: 98.50 %\n",
      "Genauigkeit für Klasse 6: 95.00 %\n",
      "Genauigkeit für Klasse 7: 99.30 %\n",
      "Genauigkeit für Klasse 8: 98.40 %\n",
      "Genauigkeit für Klasse 9: 95.00 %\n",
      "Genauigkeit für Klasse A: 99.00 %\n",
      "Genauigkeit für Klasse B: 97.30 %\n",
      "Genauigkeit für Klasse C: 83.60 %\n",
      "Genauigkeit für Klasse D: 95.30 %\n",
      "Genauigkeit für Klasse E: 97.30 %\n",
      "Genauigkeit für Klasse F: 81.40 %\n",
      "Genauigkeit für Klasse G: 94.60 %\n",
      "Genauigkeit für Klasse H: 97.50 %\n",
      "Genauigkeit für Klasse I: 64.70 %\n",
      "Genauigkeit für Klasse J: 87.60 %\n",
      "Genauigkeit für Klasse K: 79.60 %\n",
      "Genauigkeit für Klasse L: 95.20 %\n",
      "Genauigkeit für Klasse M: 92.50 %\n",
      "Genauigkeit für Klasse a: 94.90 %\n",
      "Genauigkeit für Klasse b: 92.00 %\n",
      "Genauigkeit für Klasse c: 69.60 %\n",
      "Genauigkeit für Klasse d: 98.30 %\n",
      "Genauigkeit für Klasse e: 97.30 %\n",
      "Genauigkeit für Klasse f: 75.00 %\n",
      "Genauigkeit für Klasse g: 79.50 %\n",
      "Genauigkeit für Klasse h: 96.60 %\n",
      "Genauigkeit für Klasse i: 72.80 %\n",
      "Genauigkeit für Klasse j: 78.40 %\n",
      "Genauigkeit für Klasse k: 64.20 %\n",
      "Genauigkeit für Klasse l: 44.70 %\n",
      "Genauigkeit für Klasse m: 66.90 %\n",
      "\n",
      "Precision, Recall, F1-Score pro Klasse:\n",
      "Klasse 0: Precision=0.97, Recall=0.96, F1-Score=0.96\n",
      "Klasse 1: Precision=0.53, Recall=0.64, F1-Score=0.58\n",
      "Klasse 2: Precision=0.99, Recall=0.99, F1-Score=0.99\n",
      "Klasse 3: Precision=0.99, Recall=0.99, F1-Score=0.99\n",
      "Klasse 4: Precision=0.99, Recall=0.99, F1-Score=0.99\n",
      "Klasse 5: Precision=0.99, Recall=0.98, F1-Score=0.99\n",
      "Klasse 6: Precision=0.95, Recall=0.95, F1-Score=0.95\n",
      "Klasse 7: Precision=0.99, Recall=0.99, F1-Score=0.99\n",
      "Klasse 8: Precision=0.98, Recall=0.98, F1-Score=0.98\n",
      "Klasse 9: Precision=0.89, Recall=0.95, F1-Score=0.92\n",
      "Klasse A: Precision=0.97, Recall=0.99, F1-Score=0.98\n",
      "Klasse B: Precision=0.96, Recall=0.97, F1-Score=0.96\n",
      "Klasse C: Precision=0.74, Recall=0.84, F1-Score=0.78\n",
      "Klasse D: Precision=0.94, Recall=0.95, F1-Score=0.95\n",
      "Klasse E: Precision=0.98, Recall=0.97, F1-Score=0.97\n",
      "Klasse F: Precision=0.78, Recall=0.81, F1-Score=0.80\n",
      "Klasse G: Precision=0.93, Recall=0.95, F1-Score=0.94\n",
      "Klasse H: Precision=0.96, Recall=0.97, F1-Score=0.97\n",
      "Klasse I: Precision=0.58, Recall=0.65, F1-Score=0.61\n",
      "Klasse J: Precision=0.86, Recall=0.88, F1-Score=0.87\n",
      "Klasse K: Precision=0.70, Recall=0.80, F1-Score=0.75\n",
      "Klasse L: Precision=0.93, Recall=0.95, F1-Score=0.94\n",
      "Klasse M: Precision=0.74, Recall=0.93, F1-Score=0.82\n",
      "Klasse a: Precision=0.95, Recall=0.95, F1-Score=0.95\n",
      "Klasse b: Precision=0.94, Recall=0.92, F1-Score=0.93\n",
      "Klasse c: Precision=0.79, Recall=0.70, F1-Score=0.74\n",
      "Klasse d: Precision=0.98, Recall=0.98, F1-Score=0.98\n",
      "Klasse e: Precision=0.98, Recall=0.97, F1-Score=0.98\n",
      "Klasse f: Precision=0.78, Recall=0.75, F1-Score=0.77\n",
      "Klasse g: Precision=0.90, Recall=0.80, F1-Score=0.84\n",
      "Klasse h: Precision=0.98, Recall=0.97, F1-Score=0.97\n",
      "Klasse i: Precision=0.82, Recall=0.73, F1-Score=0.77\n",
      "Klasse j: Precision=0.82, Recall=0.78, F1-Score=0.80\n",
      "Klasse k: Precision=0.74, Recall=0.64, F1-Score=0.69\n",
      "Klasse l: Precision=0.56, Recall=0.45, F1-Score=0.50\n",
      "Klasse m: Precision=0.90, Recall=0.67, F1-Score=0.77\n",
      "\n",
      "Durchschnittlicher F1-Score (gewichtet): 0.87\n",
      "\n",
      "Konfusionsmatrix:\n",
      "[[958   0   0 ...   0   0   0]\n",
      " [  0 644   0 ...   0 196   0]\n",
      " [  0   0 989 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ... 642   0   0]\n",
      " [  0 321   0 ...   0 447   0]\n",
      " [  0   0   0 ...   2   0 669]]\n",
      "\n",
      "Durchschnittliche ROC-AUC: 1.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "87.20555555555555"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(model, test_loader, device, class_list)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0d475d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in ./env/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in ./env/lib/python3.12/site-packages (from scikit-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./env/lib/python3.12/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./env/lib/python3.12/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./env/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
