{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8168e98c",
   "metadata": {},
   "source": [
    "# Timon Spichtinger Machine Learning 2 Modularbeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "113ca418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import EMNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch\n",
    "import importlib\n",
    "from Datensatz import get_emnist_test_train, show_random_samples\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddf5338",
   "metadata": {},
   "source": [
    "## 1.1 Datensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3bf0cf",
   "metadata": {},
   "source": [
    "Train und Testdaten werden aus Emnist-Datensatz geladen. Falls es zuwenige gibt werden die restlichen Augmentiert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9b5f04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ziel-ASCII: [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109]\n",
      "Anzahl Zielklassen: 36\n",
      "‚ö†Ô∏è Klasse B: nur 3878 echte Bilder ‚Äì augmentiere 2122 zus√§tzlich.\n",
      "‚ö†Ô∏è Klasse D: nur 4562 echte Bilder ‚Äì augmentiere 1438 zus√§tzlich.\n",
      "‚ö†Ô∏è Klasse E: nur 4934 echte Bilder ‚Äì augmentiere 1066 zus√§tzlich.\n",
      "‚ö†Ô∏è Klasse G: nur 2517 echte Bilder ‚Äì augmentiere 3483 zus√§tzlich.\n",
      "‚ö†Ô∏è Klasse H: nur 3152 echte Bilder ‚Äì augmentiere 2848 zus√§tzlich.\n",
      "‚ö†Ô∏è Klasse J: nur 3762 echte Bilder ‚Äì augmentiere 2238 zus√§tzlich.\n",
      "‚ö†Ô∏è Klasse K: nur 2468 echte Bilder ‚Äì augmentiere 3532 zus√§tzlich.\n",
      "‚ö†Ô∏è Klasse L: nur 5076 echte Bilder ‚Äì augmentiere 924 zus√§tzlich.\n",
      "‚ö†Ô∏è Klasse b: nur 5159 echte Bilder ‚Äì augmentiere 841 zus√§tzlich.\n",
      "‚ö†Ô∏è Klasse c: nur 2854 echte Bilder ‚Äì augmentiere 3146 zus√§tzlich.\n",
      "‚ö†Ô∏è Klasse f: nur 2561 echte Bilder ‚Äì augmentiere 3439 zus√§tzlich.\n",
      "‚ö†Ô∏è Klasse g: nur 3687 echte Bilder ‚Äì augmentiere 2313 zus√§tzlich.\n",
      "‚ö†Ô∏è Klasse i: nur 2725 echte Bilder ‚Äì augmentiere 3275 zus√§tzlich.\n",
      "‚ö†Ô∏è Klasse j: nur 1896 echte Bilder ‚Äì augmentiere 4104 zus√§tzlich.\n",
      "‚ö†Ô∏è Klasse k: nur 2491 echte Bilder ‚Äì augmentiere 3509 zus√§tzlich.\n",
      "‚ö†Ô∏è Klasse m: nur 2645 echte Bilder ‚Äì augmentiere 3355 zus√§tzlich.\n",
      "‚úÖ Trainingsdaten: torch.Size([180000, 1, 28, 28]) torch.Size([180000])\n",
      "‚úÖ Testdaten: torch.Size([36000, 1, 28, 28]) torch.Size([36000])\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test,class_list = get_emnist_test_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58605ffa",
   "metadata": {},
   "source": [
    "Stichprobe, ob der Datensatz passt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fe5cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x200 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "show_random_samples(X_test, y_test, class_list, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae2f5e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Timon/Desktop/semester6/ml2/Modularbeit/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import optuna\n",
    "from Klassifikator import get_objective, ResNet18, EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c18fcdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ger√§t\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7b06d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 10:15:32,113] A new study created in memory with name: no-name-b53304b0-b7d6-4fb9-8207-c8376a527d9d\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "get_objective() got an unexpected keyword argument 'early_stopping'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Optuna-Studie starten\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[1;32m      4\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(\u001b[43mget_objective\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m          \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m          \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m          \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m          \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mResNet18\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclass_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m          \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Beste Parameter anzeigen\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müéØ Beste Hyperparameter:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: get_objective() got an unexpected keyword argument 'early_stopping'"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Optuna-Studie starten\n",
    "# -----------------------------\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(get_objective(\n",
    "          train_dataset=train_dataset,\n",
    "          test_dataset=test_dataset,\n",
    "          device=device,\n",
    "          model=ResNet18(num_classes=len(class_list)).to(device),\n",
    "          early_stopping=EarlyStopping()), n_trials=20)\n",
    "\n",
    "# Beste Parameter anzeigen\n",
    "print(\"üéØ Beste Hyperparameter:\")\n",
    "for k, v in study.best_params.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf5b4e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'study' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Parameter f√º Finales Training \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m best_params \u001b[38;5;241m=\u001b[39m \u001b[43mstudy\u001b[49m\u001b[38;5;241m.\u001b[39mbest_params\n\u001b[1;32m      5\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39mbest_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m], shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39mbest_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m], shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'study' is not defined"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Parameter f√º Finales Training \n",
    "# -----------------------------\n",
    "best_params = study.best_params\n",
    "train_loader = DataLoader(train_dataset, batch_size=best_params[\"batch_size\"], shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=best_params[\"batch_size\"], shuffle=False)\n",
    "\n",
    "model = ResNet18(num_classes=len(class_list)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=best_params[\"lr\"], momentum=best_params[\"momentum\"])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=best_params[\"step_size\"], gamma=best_params[\"gamma\"])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e123029",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 52\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müõë Early stopping ausgel√∂st bei Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (Val Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m _1_2training(\u001b[43mtrain_loader\u001b[49m,test_loader,model,scheduler,epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "def _1_2training(train_loader,test_loader,model,scheduler,epochs = 30):\n",
    "\n",
    "    for epoch in range(30):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "            if (i + 1) % 200 == 0:\n",
    "                print(f\"üîÅ Epoch {epoch+1}, Step {i+1}/{len(train_loader)}: Batch Loss = {loss.item():.4f}\")\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # Validierung\n",
    "        val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                val_loss += criterion(outputs, labels).item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "        val_loss /= len(test_loader)\n",
    "        train_acc = 100.0 * correct_train / total_train\n",
    "        val_acc = 100.0 * correct_val / total_val\n",
    "\n",
    "        print(f\"üìä Epoch {epoch+1}: Train Acc = {train_acc:.2f}%, Val Acc = {val_acc:.2f}%, Val Loss = {val_loss:.4f}, LR = {scheduler.get_last_lr()}\")\n",
    "        early_stopping = EarlyStopping()\n",
    "        early_stopping(val_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"üõë Early stopping ausgel√∂st bei Epoch {epoch+1} (Val Loss: {val_loss:.4f})\")\n",
    "            break\n",
    "\n",
    "_1_2training(train_loader,test_loader,model,scheduler,epochs = 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bef864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modell speichern\n",
    "torch.save(model.state_dict(), './resnet18_best_hyperparams.pth')\n",
    "print(\"‚úÖ Modell gespeichert.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4baf65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gesamtgenauigkeit des Netzwerks: 83.92 %\n",
      "Genauigkeit f√ºr Klasse 0: 97.90 %\n",
      "Genauigkeit f√ºr Klasse 1: 71.70 %\n",
      "Genauigkeit f√ºr Klasse 2: 98.20 %\n",
      "Genauigkeit f√ºr Klasse 3: 98.20 %\n",
      "Genauigkeit f√ºr Klasse 4: 97.00 %\n",
      "Genauigkeit f√ºr Klasse 5: 98.40 %\n",
      "Genauigkeit f√ºr Klasse 6: 93.80 %\n",
      "Genauigkeit f√ºr Klasse 7: 98.80 %\n",
      "Genauigkeit f√ºr Klasse 8: 97.80 %\n",
      "Genauigkeit f√ºr Klasse 9: 93.50 %\n",
      "Genauigkeit f√ºr Klasse A: 98.40 %\n",
      "Genauigkeit f√ºr Klasse B: 91.20 %\n",
      "Genauigkeit f√ºr Klasse C: 91.60 %\n",
      "Genauigkeit f√ºr Klasse D: 90.10 %\n",
      "Genauigkeit f√ºr Klasse E: 93.90 %\n",
      "Genauigkeit f√ºr Klasse F: 87.40 %\n",
      "Genauigkeit f√ºr Klasse G: 89.50 %\n",
      "Genauigkeit f√ºr Klasse H: 94.50 %\n",
      "Genauigkeit f√ºr Klasse I: 52.10 %\n",
      "Genauigkeit f√ºr Klasse J: 82.30 %\n",
      "Genauigkeit f√ºr Klasse K: 78.40 %\n",
      "Genauigkeit f√ºr Klasse L: 93.30 %\n",
      "Genauigkeit f√ºr Klasse M: 58.20 %\n",
      "Genauigkeit f√ºr Klasse a: 94.50 %\n",
      "Genauigkeit f√ºr Klasse b: 89.00 %\n",
      "Genauigkeit f√ºr Klasse c: 53.90 %\n",
      "Genauigkeit f√ºr Klasse d: 96.80 %\n",
      "Genauigkeit f√ºr Klasse e: 97.20 %\n",
      "Genauigkeit f√ºr Klasse f: 64.70 %\n",
      "Genauigkeit f√ºr Klasse g: 72.10 %\n",
      "Genauigkeit f√ºr Klasse h: 96.80 %\n",
      "Genauigkeit f√ºr Klasse i: 69.30 %\n",
      "Genauigkeit f√ºr Klasse j: 71.00 %\n",
      "Genauigkeit f√ºr Klasse k: 47.50 %\n",
      "Genauigkeit f√ºr Klasse l: 40.20 %\n",
      "Genauigkeit f√ºr Klasse m: 81.90 %\n",
      "\n",
      "Precision, Recall, F1-Score pro Klasse:\n",
      "Klasse 0: Precision=0.95, Recall=0.98, F1-Score=0.96\n",
      "Klasse 1: Precision=0.48, Recall=0.72, F1-Score=0.57\n",
      "Klasse 2: Precision=0.97, Recall=0.98, F1-Score=0.98\n",
      "Klasse 3: Precision=0.99, Recall=0.98, F1-Score=0.99\n",
      "Klasse 4: Precision=0.99, Recall=0.97, F1-Score=0.98\n",
      "Klasse 5: Precision=0.97, Recall=0.98, F1-Score=0.98\n",
      "Klasse 6: Precision=0.94, Recall=0.94, F1-Score=0.94\n",
      "Klasse 7: Precision=0.99, Recall=0.99, F1-Score=0.99\n",
      "Klasse 8: Precision=0.94, Recall=0.98, F1-Score=0.96\n",
      "Klasse 9: Precision=0.87, Recall=0.94, F1-Score=0.90\n",
      "Klasse A: Precision=0.95, Recall=0.98, F1-Score=0.97\n",
      "Klasse B: Precision=0.94, Recall=0.91, F1-Score=0.93\n",
      "Klasse C: Precision=0.68, Recall=0.92, F1-Score=0.78\n",
      "Klasse D: Precision=0.94, Recall=0.90, F1-Score=0.92\n",
      "Klasse E: Precision=0.93, Recall=0.94, F1-Score=0.94\n",
      "Klasse F: Precision=0.75, Recall=0.87, F1-Score=0.81\n",
      "Klasse G: Precision=0.90, Recall=0.90, F1-Score=0.90\n",
      "Klasse H: Precision=0.93, Recall=0.94, F1-Score=0.94\n",
      "Klasse I: Precision=0.64, Recall=0.52, F1-Score=0.58\n",
      "Klasse J: Precision=0.84, Recall=0.82, F1-Score=0.83\n",
      "Klasse K: Precision=0.61, Recall=0.78, F1-Score=0.68\n",
      "Klasse L: Precision=0.90, Recall=0.93, F1-Score=0.92\n",
      "Klasse M: Precision=0.79, Recall=0.58, F1-Score=0.67\n",
      "Klasse a: Precision=0.96, Recall=0.94, F1-Score=0.95\n",
      "Klasse b: Precision=0.93, Recall=0.89, F1-Score=0.91\n",
      "Klasse c: Precision=0.79, Recall=0.54, F1-Score=0.64\n",
      "Klasse d: Precision=0.98, Recall=0.97, F1-Score=0.98\n",
      "Klasse e: Precision=0.96, Recall=0.97, F1-Score=0.97\n",
      "Klasse f: Precision=0.77, Recall=0.65, F1-Score=0.70\n",
      "Klasse g: Precision=0.82, Recall=0.72, F1-Score=0.77\n",
      "Klasse h: Precision=0.96, Recall=0.97, F1-Score=0.96\n",
      "Klasse i: Precision=0.72, Recall=0.69, F1-Score=0.70\n",
      "Klasse j: Precision=0.76, Recall=0.71, F1-Score=0.73\n",
      "Klasse k: Precision=0.66, Recall=0.47, F1-Score=0.55\n",
      "Klasse l: Precision=0.52, Recall=0.40, F1-Score=0.45\n",
      "Klasse m: Precision=0.65, Recall=0.82, F1-Score=0.73\n",
      "\n",
      "Durchschnittlicher F1-Score (gewichtet): 0.84\n",
      "\n",
      "Konfusionsmatrix:\n",
      "[[979   0   0 ...   0   0   0]\n",
      " [  0 717   0 ...   0 176   0]\n",
      " [  0   0 982 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ... 475   0   0]\n",
      " [  0 441   0 ...   0 402   0]\n",
      " [  0   0   0 ...   6   0 819]]\n",
      "\n",
      "Durchschnittliche ROC-AUC: 1.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "83.91944444444445"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(model, test_loader, device, class_list):\n",
    "    model.eval()  # Setze das Modell in den Evaluierungsmodus\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():  # Keine Gradientenberechnung, da wir nur evaluieren\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        n_class_correct = defaultdict(int)\n",
    "        n_class_samples = defaultdict(int)\n",
    "\n",
    "        # Iteriere √ºber den Testdatensatz\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)  # Bilder auf das gleiche Ger√§t verschieben (GPU oder CPU)\n",
    "            labels = labels.to(device)  # Labels auf das gleiche Ger√§t verschieben (GPU oder CPU)\n",
    "            \n",
    "            # Vorw√§rtsdurchlauf\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Vorhersagen\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            # Update der Gesamtmetriken\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Update der Metriken pro Klasse\n",
    "            for i in range(labels.size(0)):\n",
    "                label = labels[i].item()\n",
    "                pred = predicted[i].item()\n",
    "                if label == pred:\n",
    "                    n_class_correct[label] += 1\n",
    "                n_class_samples[label] += 1\n",
    "\n",
    "            # Speichere alle Labels und Vorhersagen f√ºr die Berechnung der weiteren Metriken\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "        # Berechnung der Gesamtgenauigkeit\n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        print(f'Gesamtgenauigkeit des Netzwerks: {acc:.2f} %')\n",
    "\n",
    "        # Berechnung der Klasse-genauen Genauigkeit\n",
    "        for label in sorted(n_class_samples.keys()):\n",
    "            ascii_char = class_list[label]\n",
    "            class_acc = 100.0 * n_class_correct[label] / n_class_samples[label]\n",
    "            print(f'Genauigkeit f√ºr Klasse {ascii_char}: {class_acc:.2f} %')\n",
    "\n",
    "        # Berechnung der Precision, Recall und F1-Score f√ºr jede Klasse\n",
    "        precision = precision_score(all_labels, all_predictions, average=None, labels=np.unique(all_labels))\n",
    "        recall = recall_score(all_labels, all_predictions, average=None, labels=np.unique(all_labels))\n",
    "        f1 = f1_score(all_labels, all_predictions, average=None, labels=np.unique(all_labels))\n",
    "        \n",
    "        # Berechne den durchschnittlichen F1-Score\n",
    "        avg_f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "        \n",
    "        print(\"\\nPrecision, Recall, F1-Score pro Klasse:\")\n",
    "        for i, ascii_char in enumerate(class_list):\n",
    "            print(f\"Klasse {ascii_char}: Precision={precision[i]:.2f}, Recall={recall[i]:.2f}, F1-Score={f1[i]:.2f}\")\n",
    "        \n",
    "        print(f\"\\nDurchschnittlicher F1-Score (gewichtet): {avg_f1:.2f}\")\n",
    "\n",
    "        # Berechnung der Konfusionsmatrix\n",
    "        cm = confusion_matrix(all_labels, all_predictions)\n",
    "        print(f\"\\nKonfusionsmatrix:\\n{cm}\")\n",
    "\n",
    "        # Berechnung der ROC-AUC (f√ºr Multiklassen kann man dies auch f√ºr jedes Label einzeln berechnen)\n",
    "        try:\n",
    "            roc_auc = roc_auc_score(all_labels, model_output_to_probs(model, test_loader, device), multi_class='ovr', average='weighted')\n",
    "            print(f\"\\nDurchschnittliche ROC-AUC: {roc_auc:.2f}\")\n",
    "        except ValueError:\n",
    "            print(\"\\nROC-AUC konnte nicht berechnet werden (m√∂glicherweise nicht geeignet f√ºr das Problem).\")\n",
    "\n",
    "        return acc\n",
    "\n",
    "# Hilfsfunktion zur Berechnung der ROC-AUC f√ºr das Multiklassenproblem\n",
    "def model_output_to_probs(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    with torch.no_grad():\n",
    "        for images, _ in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    return np.array(all_probs)\n",
    "\n",
    "# Beispielaufruf\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # W√§hle GPU, wenn verf√ºgbar\n",
    "\n",
    "# Modell auf das Ger√§t (GPU/CPU) verschieben\n",
    "model = model.to(device)\n",
    "\n",
    "# Jetzt den Evaluierungscode aufrufen\n",
    "evaluate_model(model, test_loader, device, class_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e153ab6",
   "metadata": {},
   "source": [
    "# 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa0bb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_type_labeled_dataloaders(X_train, y_train, X_test, y_test, class_list, batch_size):\n",
    "    def get_type_labels(y_tensor):\n",
    "        type_labels = []\n",
    "        for label in y_tensor:\n",
    "            char = str(class_list[int(label)])  # Ensure it's a string\n",
    "            \n",
    "            if char.isdigit():\n",
    "                type_labels.append(0)  # Ziffer\n",
    "            elif char.isupper():\n",
    "                type_labels.append(1)  # Gro√übuchstabe\n",
    "            else:\n",
    "                type_labels.append(2)  # Kleinbuchstabe\n",
    "        return torch.tensor(type_labels, dtype=torch.long)\n",
    "\n",
    "    y_train_type = get_type_labels(y_train)\n",
    "    y_test_type = get_type_labels(y_test)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train, y_train, y_train_type)\n",
    "    test_dataset = TensorDataset(X_test, y_test, y_test_type)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611a1553",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605e97f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = create_type_labeled_dataloaders(\n",
    "    X_train, y_train, X_test, y_test,\n",
    "    class_list=class_list,\n",
    "    batch_size=best_params[\"batch_size\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a43519a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1ade3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type_label_tensor(label_tensor):\n",
    "    class_list = list('0123456789ABCDEFGHIJKLMabcdefghijklm')\n",
    "    label_to_class = {i: c for i, c in enumerate(class_list)}\n",
    "    \n",
    "    type_labels = []\n",
    "    for label in label_tensor:\n",
    "        char = label_to_class[int(label)]\n",
    "        if char.isdigit():\n",
    "            type_labels.append(0)\n",
    "        elif char.isupper():\n",
    "            type_labels.append(1)\n",
    "        else:\n",
    "            type_labels.append(2)\n",
    "    return torch.tensor(type_labels, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa091c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_type = get_type_label_tensor(y_train)\n",
    "y_test_type = get_type_label_tensor(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391d2ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train, y_train, y_train_type)\n",
    "test_dataset = TensorDataset(X_test, y_test, y_test_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f7f98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispielhafte Klasse-zu-Typ-Zuordnung: 0 = Gro√ü, 1 = Klein, 2 = Ziffer\n",
    "def get_type_label_tensor(y):\n",
    "    type_labels = []\n",
    "    for label in y:\n",
    "        char = class_list[label]\n",
    "        if char.isdigit():\n",
    "            type_labels.append(2)\n",
    "        elif char.isupper():\n",
    "            type_labels.append(0)\n",
    "        else:\n",
    "            type_labels.append(1)\n",
    "    return torch.tensor(type_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbcbbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d475d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TypeClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TypeClassifier, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 7 * 7, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return F.softmax(self.fc(x), dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da19808",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModularClassifier(nn.Module):\n",
    "    def __init__(self, tm1, tm2, class_type_map):\n",
    "        super(ModularClassifier, self).__init__()\n",
    "        self.tm1 = tm1\n",
    "        self.tm2 = tm2\n",
    "        self.class_type_map = torch.tensor(class_type_map, dtype=torch.long)  # L√§nge 36\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_cls = self.tm1(x)  # shape (B, 36)\n",
    "        out_type = self.tm2(x)  # shape (B, 3)\n",
    "\n",
    "        type_probs = out_type[:, self.class_type_map.to(x.device)]  # shape (B, 36)\n",
    "        final_out = out_cls * type_probs  # Elementweise Multiplikation\n",
    "\n",
    "        return final_out, out_cls, out_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff7ec0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'isdigit'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m class_type_map = []\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m class_list:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mc\u001b[49m\u001b[43m.\u001b[49m\u001b[43misdigit\u001b[49m():\n\u001b[32m      5\u001b[39m         class_type_map.append(\u001b[32m2\u001b[39m)\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m c.isupper():\n",
      "\u001b[31mAttributeError\u001b[39m: 'int' object has no attribute 'isdigit'"
     ]
    }
   ],
   "source": [
    "# class_list = ['0', '1', ..., 'a', 'b', ...]\n",
    "class_type_map = []\n",
    "for c in class_list:\n",
    "    if c.isdigit():\n",
    "        class_type_map.append(2)\n",
    "    elif c.isupper():\n",
    "        class_type_map.append(0)\n",
    "    else:\n",
    "        class_type_map.append(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567bee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tm1 = ResNet18(num_classes=len(class_list))\n",
    "\n",
    "modular_model = ModularClassifier(\n",
    "    tm1,\n",
    "    tm2=TypeClassifier(),\n",
    "    class_type_map=class_type_map\n",
    ").to(device)\n",
    "\n",
    "criterion_cls = nn.CrossEntropyLoss()\n",
    "criterion_type = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(modular_model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce4c6de",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (36) must match the size of tensor b (0) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m labels_cls = labels_cls.to(device)\n\u001b[32m      8\u001b[39m labels_type = labels_type.to(device)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m final_out, out_cls, out_type = \u001b[43mmodular_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m loss_cls = criterion_cls(out_cls, labels_cls)\n\u001b[32m     13\u001b[39m loss_type = criterion_type(out_type, labels_type)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ML2Modularbeit/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ML2Modularbeit/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mModularClassifier.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     10\u001b[39m out_type = \u001b[38;5;28mself\u001b[39m.tm2(x)  \u001b[38;5;66;03m# shape (B, 3)\u001b[39;00m\n\u001b[32m     12\u001b[39m type_probs = out_type[:, \u001b[38;5;28mself\u001b[39m.class_type_map.to(x.device)]  \u001b[38;5;66;03m# shape (B, 36)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m final_out = \u001b[43mout_cls\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_probs\u001b[49m  \u001b[38;5;66;03m# Elementweise Multiplikation\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m final_out, out_cls, out_type\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (36) must match the size of tensor b (0) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    modular_model.train()\n",
    "    total_loss = 0.0  # ‚úÖ richtig initialisieren\n",
    "\n",
    "    for images, labels_cls, labels_type in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels_cls = labels_cls.to(device)\n",
    "        labels_type = labels_type.to(device)\n",
    "\n",
    "        final_out, out_cls, out_type = modular_model(images)\n",
    "\n",
    "        loss_cls = criterion_cls(out_cls, labels_cls)\n",
    "        loss_type = criterion_type(out_type, labels_type)\n",
    "        loss = loss_cls + 0.5 * loss_type\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()  # ‚úÖ jetzt ist total_loss eine float\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e2e7ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8fdf48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
