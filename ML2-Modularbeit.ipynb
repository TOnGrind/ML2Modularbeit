{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8168e98c",
   "metadata": {},
   "source": [
    "# Timon Spichtinger Machine Learning 2 Modularbeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "113ca418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import EMNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch\n",
    "import importlib\n",
    "\n",
    "\n",
    "from Datensatz import get_emnist_test_train, show_random_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9b5f04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ziel-ASCII: [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109]\n",
      "Anzahl Zielklassen: 36\n",
      "⚠️ Klasse B: nur 3878 echte Bilder – augmentiere 2122 zusätzlich.\n",
      "⚠️ Klasse D: nur 4562 echte Bilder – augmentiere 1438 zusätzlich.\n",
      "⚠️ Klasse E: nur 4934 echte Bilder – augmentiere 1066 zusätzlich.\n",
      "⚠️ Klasse G: nur 2517 echte Bilder – augmentiere 3483 zusätzlich.\n",
      "⚠️ Klasse H: nur 3152 echte Bilder – augmentiere 2848 zusätzlich.\n",
      "⚠️ Klasse J: nur 3762 echte Bilder – augmentiere 2238 zusätzlich.\n",
      "⚠️ Klasse K: nur 2468 echte Bilder – augmentiere 3532 zusätzlich.\n",
      "⚠️ Klasse L: nur 5076 echte Bilder – augmentiere 924 zusätzlich.\n",
      "⚠️ Klasse b: nur 5159 echte Bilder – augmentiere 841 zusätzlich.\n",
      "⚠️ Klasse c: nur 2854 echte Bilder – augmentiere 3146 zusätzlich.\n",
      "⚠️ Klasse f: nur 2561 echte Bilder – augmentiere 3439 zusätzlich.\n",
      "⚠️ Klasse g: nur 3687 echte Bilder – augmentiere 2313 zusätzlich.\n",
      "⚠️ Klasse i: nur 2725 echte Bilder – augmentiere 3275 zusätzlich.\n",
      "⚠️ Klasse j: nur 1896 echte Bilder – augmentiere 4104 zusätzlich.\n",
      "⚠️ Klasse k: nur 2491 echte Bilder – augmentiere 3509 zusätzlich.\n",
      "⚠️ Klasse m: nur 2645 echte Bilder – augmentiere 3355 zusätzlich.\n",
      "✅ Trainingsdaten: torch.Size([180000, 1, 28, 28]) torch.Size([180000])\n",
      "✅ Testdaten: torch.Size([36000, 1, 28, 28]) torch.Size([36000])\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test,classlist = get_emnist_test_train()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39fe5cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x200 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "show_random_samples(X_test, y_test, classlist, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "295aecc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c18fcdfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Step [200/2813], Loss: 2.3234\n",
      "Epoch [1/30], Step [400/2813], Loss: 1.4336\n",
      "Epoch [1/30], Step [600/2813], Loss: 1.2543\n",
      "Epoch [1/30], Step [800/2813], Loss: 0.9106\n",
      "Epoch [1/30], Step [1000/2813], Loss: 1.0892\n",
      "Epoch [1/30], Step [1200/2813], Loss: 0.8325\n",
      "Epoch [1/30], Step [1400/2813], Loss: 0.9452\n",
      "Epoch [1/30], Step [1600/2813], Loss: 0.7520\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 79\u001b[0m\n\u001b[0;32m     76\u001b[0m images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     77\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 79\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     82\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\Timon\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Timon\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Timon\\Desktop\\semester6\\ml2\\Modularbeit\\Klassifikator.py:89\u001b[0m, in \u001b[0;36mEMNISTNetPlus.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 89\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_block1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_block2(x)\n\u001b[0;32m     91\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_block3(x)\n",
      "File \u001b[1;32mc:\\Users\\Timon\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Timon\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Timon\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\container.py:240\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 240\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Timon\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Timon\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Timon\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:70\u001b[0m, in \u001b[0;36mDropout.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Timon\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\functional.py:1425\u001b[0m, in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[0;32m   1423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1424\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m-> 1425\u001b[0m     _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1426\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, RandomAffine, Compose\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "from Klassifikator import EMNISTNetPlus\n",
    "\n",
    "# -----------------------------\n",
    "# Geräte-Konfiguration & Hyperparameter\n",
    "# -----------------------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_epochs = 30\n",
    "batch_size = 64\n",
    "initial_lr = 0.08  # Anfangslernrate\n",
    "\n",
    "# -----------------------------\n",
    "# Klassenliste (direkte Labels)\n",
    "# -----------------------------\n",
    "class_list = list('0123456789ABCDEFGHIJKLMabcdefghijklm')  # 36 Zeichen\n",
    "\n",
    "# -----------------------------\n",
    "# CNN-Modell\n",
    "# -----------------------------\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,class_list):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, len(class_list))  # 36 Klassen\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))   # [B, 6, 14, 14]\n",
    "        x = self.pool(F.relu(self.conv2(x)))   # [B, 16, 5, 5]\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "# -----------------------------\n",
    "# Lade Daten (angenommen du hast X_train, y_train, X_test, y_test vorher vorbereitet)\n",
    "# -----------------------------\n",
    "def transform_to_rgb_and_resize(tensor_batch):\n",
    "    return torch.stack([transforms.Resize((32, 32))(img.repeat(3, 1, 1)) for img in tensor_batch])\n",
    "\n",
    "# Wandelt Graustufen-Bilder in 3-Kanal-RGB um und resized sie auf 32x32\n",
    "X_train = transform_to_rgb_and_resize(X_train)\n",
    "X_test = transform_to_rgb_and_resize(X_test)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# -----------------------------\n",
    "# Training\n",
    "# -----------------------------\n",
    "model = EMNISTNetPlus(len(class_list)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=initial_lr, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.7)  # Lernrate sinkt alle 3 Epochen\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if (i + 1) % 200 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    scheduler.step()\n",
    "    print(f'🔁 Epoch {epoch+1} abgeschlossen. Durchschnittlicher Loss: {running_loss / len(train_loader):.4f}')\n",
    "\n",
    "print(\"✅ Training abgeschlossen.\")\n",
    "\n",
    "# -----------------------------\n",
    "# Modell speichern\n",
    "# -----------------------------\n",
    "torch.save(model.state_dict(), './emnist_cnn.pth')\n",
    "\n",
    "# -----------------------------\n",
    "# Modell testen\n",
    "# -----------------------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = defaultdict(int)\n",
    "    n_class_samples = defaultdict(int)\n",
    "\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        for i in range(labels.size(0)):\n",
    "            label = labels[i].item()\n",
    "            pred = predicted[i].item()\n",
    "            if label == pred:\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Gesamtgenauigkeit des Netzwerks: {acc:.2f} %')\n",
    "\n",
    "    for label in sorted(n_class_samples.keys()):\n",
    "        ascii_char = class_list[label]\n",
    "        acc = 100.0 * n_class_correct[label] / n_class_samples[label]\n",
    "        print(f'Genauigkeit für Klasse {ascii_char}: {acc:.2f} %')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbcbbbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
