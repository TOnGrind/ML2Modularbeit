{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8168e98c",
   "metadata": {},
   "source": [
    "# Timon Spichtinger Machine Learning 2 Modularbeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "113ca418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import EMNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch\n",
    "import importlib\n",
    "from Datensatz import get_emnist_test_train, show_random_samples\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3bf0cf",
   "metadata": {},
   "source": [
    "Train und Testdaten werden aus Emnist-Datensatz geladen. Falls es zuwenige gibt werden die restlichen Augmentiert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9b5f04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ziel-ASCII: [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109]\n",
      "Anzahl Zielklassen: 36\n",
      "⚠️ Klasse B: nur 3878 echte Bilder – augmentiere 2122 zusätzlich.\n",
      "⚠️ Klasse D: nur 4562 echte Bilder – augmentiere 1438 zusätzlich.\n",
      "⚠️ Klasse E: nur 4934 echte Bilder – augmentiere 1066 zusätzlich.\n",
      "⚠️ Klasse G: nur 2517 echte Bilder – augmentiere 3483 zusätzlich.\n",
      "⚠️ Klasse H: nur 3152 echte Bilder – augmentiere 2848 zusätzlich.\n",
      "⚠️ Klasse J: nur 3762 echte Bilder – augmentiere 2238 zusätzlich.\n",
      "⚠️ Klasse K: nur 2468 echte Bilder – augmentiere 3532 zusätzlich.\n",
      "⚠️ Klasse L: nur 5076 echte Bilder – augmentiere 924 zusätzlich.\n",
      "⚠️ Klasse b: nur 5159 echte Bilder – augmentiere 841 zusätzlich.\n",
      "⚠️ Klasse c: nur 2854 echte Bilder – augmentiere 3146 zusätzlich.\n",
      "⚠️ Klasse f: nur 2561 echte Bilder – augmentiere 3439 zusätzlich.\n",
      "⚠️ Klasse g: nur 3687 echte Bilder – augmentiere 2313 zusätzlich.\n",
      "⚠️ Klasse i: nur 2725 echte Bilder – augmentiere 3275 zusätzlich.\n",
      "⚠️ Klasse j: nur 1896 echte Bilder – augmentiere 4104 zusätzlich.\n",
      "⚠️ Klasse k: nur 2491 echte Bilder – augmentiere 3509 zusätzlich.\n",
      "⚠️ Klasse m: nur 2645 echte Bilder – augmentiere 3355 zusätzlich.\n",
      "✅ Trainingsdaten: torch.Size([180000, 1, 28, 28]) torch.Size([180000])\n",
      "✅ Testdaten: torch.Size([36000, 1, 28, 28]) torch.Size([36000])\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test,class_list = get_emnist_test_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65711290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58605ffa",
   "metadata": {},
   "source": [
    "Stichprobe, ob der Datensatz passt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fe5cf7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mDatensatz\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_emnist_test_train, show_random_samples\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mshow_random_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ML2Modularbeit/Datensatz.py:162\u001b[39m, in \u001b[36mshow_random_samples\u001b[39m\u001b[34m(X, y, class_list, n)\u001b[39m\n\u001b[32m    160\u001b[39m img = X[idx].squeeze().numpy()\n\u001b[32m    161\u001b[39m label = y[idx].item()\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m ascii_label = \u001b[38;5;28;43mchr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclass_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Neues Mapping per Liste\u001b[39;00m\n\u001b[32m    164\u001b[39m plt.subplot(\u001b[32m1\u001b[39m, n, i + \u001b[32m1\u001b[39m)\n\u001b[32m    165\u001b[39m plt.imshow(img, cmap=\u001b[33m'\u001b[39m\u001b[33mgray\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: 'str' object cannot be interpreted as an integer"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "show_random_samples(X_test, y_test, class_list, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295aecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2f5e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/timon/ML2Modularbeit/env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import optuna\n",
    "from Klassifikator import get_objective, ResNet18, EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18fcdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Gerät\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7b06d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 16:06:58,354] A new study created in memory with name: no-name-b88dfb95-d515-4995-9e91-d0270bb3ce64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 Epoch 1: Val Loss = 0.4365\n",
      "📉 Epoch 2: Val Loss = 0.3791\n",
      "📉 Epoch 3: Val Loss = 0.3414\n",
      "📉 Epoch 4: Val Loss = 0.3468\n",
      "📉 Epoch 5: Val Loss = 0.3380\n",
      "📉 Epoch 6: Val Loss = 0.3432\n",
      "📉 Epoch 7: Val Loss = 0.3436\n",
      "📉 Epoch 8: Val Loss = 0.3500\n",
      "⛔ Early Stopping in Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 16:09:54,691] Trial 0 finished with value: 0.8636666666666667 and parameters: {'batch_size': 144, 'lr': 0.00878745466219313, 'momentum': 0.8761919333390481, 'step_size': 2, 'gamma': 0.6462000164855322}. Best is trial 0 with value: 0.8636666666666667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 16:10:33,988] Trial 1 finished with value: 0.8358888888888889 and parameters: {'batch_size': 64, 'lr': 0.014539374616698186, 'momentum': 0.9437228887878149, 'step_size': 3, 'gamma': 0.8280132658022766}. Best is trial 0 with value: 0.8636666666666667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 16:10:56,167] Trial 2 finished with value: 0.8618888888888889 and parameters: {'batch_size': 128, 'lr': 0.03006734577307517, 'momentum': 0.6020240756710974, 'step_size': 2, 'gamma': 0.6099536853296973}. Best is trial 0 with value: 0.8636666666666667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 16:11:26,861] Trial 3 finished with value: 0.8646666666666667 and parameters: {'batch_size': 128, 'lr': 0.004749605691251302, 'momentum': 0.8478575213721979, 'step_size': 4, 'gamma': 0.6593327373936422}. Best is trial 3 with value: 0.8646666666666667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 16:13:01,889] Trial 4 finished with value: 0.8655555555555555 and parameters: {'batch_size': 64, 'lr': 0.002390113059508385, 'momentum': 0.8951436451128691, 'step_size': 2, 'gamma': 0.5435493286678656}. Best is trial 4 with value: 0.8655555555555555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 16:13:44,453] Trial 5 finished with value: 0.8668888888888889 and parameters: {'batch_size': 256, 'lr': 0.0014184545123662857, 'momentum': 0.8727599858714303, 'step_size': 5, 'gamma': 0.6547982400849873}. Best is trial 5 with value: 0.8668888888888889.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 16:14:26,768] Trial 6 finished with value: 0.8675 and parameters: {'batch_size': 256, 'lr': 0.0002020115727532931, 'momentum': 0.7126039702163649, 'step_size': 3, 'gamma': 0.5923591267556638}. Best is trial 6 with value: 0.8675.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 16:15:19,891] Trial 7 finished with value: 0.8673333333333333 and parameters: {'batch_size': 144, 'lr': 0.0007504913635155087, 'momentum': 0.9259886031654467, 'step_size': 2, 'gamma': 0.6143308627196821}. Best is trial 6 with value: 0.8675.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 16:16:12,715] Trial 8 finished with value: 0.8661666666666666 and parameters: {'batch_size': 144, 'lr': 0.002701386113785338, 'momentum': 0.9396761761801506, 'step_size': 4, 'gamma': 0.9057116507953507}. Best is trial 6 with value: 0.8675.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 16:17:06,010] Trial 9 finished with value: 0.8693611111111111 and parameters: {'batch_size': 128, 'lr': 0.0004292488627734422, 'momentum': 0.9084211670437567, 'step_size': 5, 'gamma': 0.7013709727141801}. Best is trial 9 with value: 0.8693611111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 16:17:59,175] Trial 10 finished with value: 0.869 and parameters: {'batch_size': 128, 'lr': 0.0002325508361360403, 'momentum': 0.7777699710634409, 'step_size': 5, 'gamma': 0.7603758873343355}. Best is trial 9 with value: 0.8693611111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 16:18:52,451] Trial 11 finished with value: 0.86875 and parameters: {'batch_size': 128, 'lr': 0.00011381064972299301, 'momentum': 0.7620397613857819, 'step_size': 5, 'gamma': 0.7756794830406036}. Best is trial 9 with value: 0.8693611111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 16:19:45,738] Trial 12 finished with value: 0.869 and parameters: {'batch_size': 128, 'lr': 0.00040638538386665547, 'momentum': 0.7864462681060898, 'step_size': 5, 'gamma': 0.7411587976573466}. Best is trial 9 with value: 0.8693611111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 16:20:37,805] Trial 13 finished with value: 0.8688888888888889 and parameters: {'batch_size': 128, 'lr': 0.0003762738240683466, 'momentum': 0.6670862553222701, 'step_size': 4, 'gamma': 0.8222677299606982}. Best is trial 9 with value: 0.8693611111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 16:21:30,875] Trial 14 finished with value: 0.8541111111111112 and parameters: {'batch_size': 128, 'lr': 0.08903531684534785, 'momentum': 0.8137681818070223, 'step_size': 5, 'gamma': 0.7253019658288362}. Best is trial 9 with value: 0.8693611111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 16:22:23,553] Trial 15 finished with value: 0.86375 and parameters: {'batch_size': 128, 'lr': 0.0008154048055718762, 'momentum': 0.7371417016413558, 'step_size': 4, 'gamma': 0.9376690361030123}. Best is trial 9 with value: 0.8693611111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 16:23:16,714] Trial 16 finished with value: 0.8644166666666667 and parameters: {'batch_size': 128, 'lr': 0.00012099851570661097, 'momentum': 0.8123277773377352, 'step_size': 5, 'gamma': 0.8031968817723252}. Best is trial 9 with value: 0.8693611111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 16:24:50,581] Trial 17 finished with value: 0.8651666666666666 and parameters: {'batch_size': 64, 'lr': 0.0003460860751662594, 'momentum': 0.6907489944100588, 'step_size': 5, 'gamma': 0.5033185767176309}. Best is trial 9 with value: 0.8693611111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 16:25:32,503] Trial 18 finished with value: 0.86625 and parameters: {'batch_size': 256, 'lr': 0.0008946390523458848, 'momentum': 0.6367507904595922, 'step_size': 3, 'gamma': 0.6938109735658354}. Best is trial 9 with value: 0.8693611111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Early Stopping in Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 16:26:25,090] Trial 19 finished with value: 0.8665833333333334 and parameters: {'batch_size': 128, 'lr': 0.00031169539821554855, 'momentum': 0.8294273166429003, 'step_size': 4, 'gamma': 0.8719591603627624}. Best is trial 9 with value: 0.8693611111111111.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Beste Hyperparameter:\n",
      "batch_size: 128\n",
      "lr: 0.0004292488627734422\n",
      "momentum: 0.9084211670437567\n",
      "step_size: 5\n",
      "gamma: 0.7013709727141801\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Optuna-Studie starten\n",
    "# -----------------------------\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(get_objective(\n",
    "          train_dataset=train_dataset,\n",
    "          test_dataset=test_dataset,\n",
    "          device=device,\n",
    "          model=ResNet18(num_classes=len(class_list)).to(device),\n",
    "          early_stopping=EarlyStopping(patience=4)), n_trials=20)\n",
    "\n",
    "# Beste Parameter anzeigen\n",
    "print(\"🎯 Beste Hyperparameter:\")\n",
    "for k, v in study.best_params.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf5b4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Finales Training mit besten Parametern \n",
    "# -----------------------------\n",
    "best_params = study.best_params\n",
    "train_loader = DataLoader(train_dataset, batch_size=best_params[\"batch_size\"], shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=best_params[\"batch_size\"], shuffle=False)\n",
    "\n",
    "model = ResNet18(num_classes=len(class_list)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=best_params[\"lr\"], momentum=best_params[\"momentum\"])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=best_params[\"step_size\"], gamma=best_params[\"gamma\"])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e123029",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        if (i + 1) % 200 == 0:\n",
    "            print(f\"🔁 Epoch {epoch+1}, Step {i+1}/{len(train_loader)}: Batch Loss = {loss.item():.4f}\")\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # Validierung\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "    val_loss /= len(test_loader)\n",
    "    train_acc = 100.0 * correct_train / total_train\n",
    "    val_acc = 100.0 * correct_val / total_val\n",
    "\n",
    "    print(f\"📊 Epoch {epoch+1}: Train Acc = {train_acc:.2f}%, Val Acc = {val_acc:.2f}%, Val Loss = {val_loss:.4f}, LR = {scheduler.get_last_lr()}\")\n",
    "    early_stopping = EarlyStopping()\n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(f\"🛑 Early stopping ausgelöst bei Epoch {epoch+1} (Val Loss: {val_loss:.4f})\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bef864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modell speichern\n",
    "torch.save(model.state_dict(), './resnet18_best_hyperparams.pth')\n",
    "print(\"✅ Modell gespeichert.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4baf65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gesamtgenauigkeit des Netzwerks: 3.17 %\n",
      "Genauigkeit für Klasse 48: 0.00 %\n",
      "Genauigkeit für Klasse 49: 0.00 %\n",
      "Genauigkeit für Klasse 50: 0.00 %\n",
      "Genauigkeit für Klasse 51: 0.00 %\n",
      "Genauigkeit für Klasse 52: 0.00 %\n",
      "Genauigkeit für Klasse 53: 0.00 %\n",
      "Genauigkeit für Klasse 54: 0.00 %\n",
      "Genauigkeit für Klasse 55: 0.00 %\n",
      "Genauigkeit für Klasse 56: 0.00 %\n",
      "Genauigkeit für Klasse 57: 0.00 %\n",
      "Genauigkeit für Klasse 65: 0.00 %\n",
      "Genauigkeit für Klasse 66: 11.50 %\n",
      "Genauigkeit für Klasse 67: 0.00 %\n",
      "Genauigkeit für Klasse 68: 0.00 %\n",
      "Genauigkeit für Klasse 69: 0.00 %\n",
      "Genauigkeit für Klasse 70: 0.00 %\n",
      "Genauigkeit für Klasse 71: 0.00 %\n",
      "Genauigkeit für Klasse 72: 2.70 %\n",
      "Genauigkeit für Klasse 73: 0.00 %\n",
      "Genauigkeit für Klasse 74: 3.00 %\n",
      "Genauigkeit für Klasse 75: 0.00 %\n",
      "Genauigkeit für Klasse 76: 0.00 %\n",
      "Genauigkeit für Klasse 77: 0.00 %\n",
      "Genauigkeit für Klasse 97: 0.00 %\n",
      "Genauigkeit für Klasse 98: 0.00 %\n",
      "Genauigkeit für Klasse 99: 0.00 %\n",
      "Genauigkeit für Klasse 100: 0.00 %\n",
      "Genauigkeit für Klasse 101: 97.00 %\n",
      "Genauigkeit für Klasse 102: 0.00 %\n",
      "Genauigkeit für Klasse 103: 0.00 %\n",
      "Genauigkeit für Klasse 104: 0.00 %\n",
      "Genauigkeit für Klasse 105: 0.00 %\n",
      "Genauigkeit für Klasse 106: 0.00 %\n",
      "Genauigkeit für Klasse 107: 0.00 %\n",
      "Genauigkeit für Klasse 108: 0.00 %\n",
      "Genauigkeit für Klasse 109: 0.00 %\n",
      "\n",
      "Precision, Recall, F1-Score pro Klasse:\n",
      "Klasse 48: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 49: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 50: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 51: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 52: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 53: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 54: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 55: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 56: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 57: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 65: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 66: Precision=0.04, Recall=0.12, F1-Score=0.05\n",
      "Klasse 67: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 68: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 69: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 70: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 71: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 72: Precision=0.04, Recall=0.03, F1-Score=0.03\n",
      "Klasse 73: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 74: Precision=0.02, Recall=0.03, F1-Score=0.02\n",
      "Klasse 75: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 76: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 77: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 97: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 98: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 99: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 100: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 101: Precision=0.03, Recall=0.97, F1-Score=0.06\n",
      "Klasse 102: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 103: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 104: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 105: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 106: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 107: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 108: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "Klasse 109: Precision=0.00, Recall=0.00, F1-Score=0.00\n",
      "\n",
      "Durchschnittlicher F1-Score (gewichtet): 0.00\n",
      "\n",
      "Konfusionsmatrix:\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/timon/ML2Modularbeit/env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Durchschnittliche ROC-AUC: 0.53\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.172222222222222"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(model, test_loader, device, class_list):\n",
    "    model.eval()  # Setze das Modell in den Evaluierungsmodus\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():  # Keine Gradientenberechnung, da wir nur evaluieren\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        n_class_correct = defaultdict(int)\n",
    "        n_class_samples = defaultdict(int)\n",
    "\n",
    "        # Iteriere über den Testdatensatz\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)  # Bilder auf das gleiche Gerät verschieben (GPU oder CPU)\n",
    "            labels = labels.to(device)  # Labels auf das gleiche Gerät verschieben (GPU oder CPU)\n",
    "            \n",
    "            # Vorwärtsdurchlauf\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Vorhersagen\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            # Update der Gesamtmetriken\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Update der Metriken pro Klasse\n",
    "            for i in range(labels.size(0)):\n",
    "                label = labels[i].item()\n",
    "                pred = predicted[i].item()\n",
    "                if label == pred:\n",
    "                    n_class_correct[label] += 1\n",
    "                n_class_samples[label] += 1\n",
    "\n",
    "            # Speichere alle Labels und Vorhersagen für die Berechnung der weiteren Metriken\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "        # Berechnung der Gesamtgenauigkeit\n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        print(f'Gesamtgenauigkeit des Netzwerks: {acc:.2f} %')\n",
    "\n",
    "        # Berechnung der Klasse-genauen Genauigkeit\n",
    "        for label in sorted(n_class_samples.keys()):\n",
    "            ascii_char = class_list[label]\n",
    "            class_acc = 100.0 * n_class_correct[label] / n_class_samples[label]\n",
    "            print(f'Genauigkeit für Klasse {ascii_char}: {class_acc:.2f} %')\n",
    "\n",
    "        # Berechnung der Precision, Recall und F1-Score für jede Klasse\n",
    "        precision = precision_score(all_labels, all_predictions, average=None, labels=np.unique(all_labels))\n",
    "        recall = recall_score(all_labels, all_predictions, average=None, labels=np.unique(all_labels))\n",
    "        f1 = f1_score(all_labels, all_predictions, average=None, labels=np.unique(all_labels))\n",
    "        \n",
    "        # Berechne den durchschnittlichen F1-Score\n",
    "        avg_f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "        \n",
    "        print(\"\\nPrecision, Recall, F1-Score pro Klasse:\")\n",
    "        for i, ascii_char in enumerate(class_list):\n",
    "            print(f\"Klasse {ascii_char}: Precision={precision[i]:.2f}, Recall={recall[i]:.2f}, F1-Score={f1[i]:.2f}\")\n",
    "        \n",
    "        print(f\"\\nDurchschnittlicher F1-Score (gewichtet): {avg_f1:.2f}\")\n",
    "\n",
    "        # Berechnung der Konfusionsmatrix\n",
    "        cm = confusion_matrix(all_labels, all_predictions)\n",
    "        print(f\"\\nKonfusionsmatrix:\\n{cm}\")\n",
    "\n",
    "        # Berechnung der ROC-AUC (für Multiklassen kann man dies auch für jedes Label einzeln berechnen)\n",
    "        try:\n",
    "            roc_auc = roc_auc_score(all_labels, model_output_to_probs(model, test_loader, device), multi_class='ovr', average='weighted')\n",
    "            print(f\"\\nDurchschnittliche ROC-AUC: {roc_auc:.2f}\")\n",
    "        except ValueError:\n",
    "            print(\"\\nROC-AUC konnte nicht berechnet werden (möglicherweise nicht geeignet für das Problem).\")\n",
    "\n",
    "        return acc\n",
    "\n",
    "# Hilfsfunktion zur Berechnung der ROC-AUC für das Multiklassenproblem\n",
    "def model_output_to_probs(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    with torch.no_grad():\n",
    "        for images, _ in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    return np.array(all_probs)\n",
    "\n",
    "# Beispielaufruf\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # Wähle GPU, wenn verfügbar\n",
    "\n",
    "# Modell auf das Gerät (GPU/CPU) verschieben\n",
    "model = model.to(device)\n",
    "\n",
    "# Jetzt den Evaluierungscode aufrufen\n",
    "evaluate_model(model, test_loader, device, class_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e153ab6",
   "metadata": {},
   "source": [
    "# 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b2c2db",
   "metadata": {},
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d77fd76",
   "metadata": {},
   "source": [
    "list('0123456789ABCDEFGHIJKLMabcdefghijklm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa0bb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_type_labeled_dataloaders(X_train, y_train, X_test, y_test, class_list, batch_size):\n",
    "    def get_type_labels(y_tensor):\n",
    "        type_labels = []\n",
    "        for label in y_tensor:\n",
    "            char = str(class_list[int(label)])  # Ensure it's a string\n",
    "            \n",
    "            if char.isdigit():\n",
    "                type_labels.append(0)  # Ziffer\n",
    "            elif char.isupper():\n",
    "                type_labels.append(1)  # Großbuchstabe\n",
    "            else:\n",
    "                type_labels.append(2)  # Kleinbuchstabe\n",
    "        return torch.tensor(type_labels, dtype=torch.long)\n",
    "\n",
    "    y_train_type = get_type_labels(y_train)\n",
    "    y_test_type = get_type_labels(y_test)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train, y_train, y_train_type)\n",
    "    test_dataset = TensorDataset(X_test, y_test, y_test_type)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611a1553",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605e97f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = create_type_labeled_dataloaders(\n",
    "    X_train, y_train, X_test, y_test,\n",
    "    class_list=class_list,\n",
    "    batch_size=best_params[\"batch_size\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a43519a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1ade3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type_label_tensor(label_tensor):\n",
    "    class_list = list('0123456789ABCDEFGHIJKLMabcdefghijklm')\n",
    "    label_to_class = {i: c for i, c in enumerate(class_list)}\n",
    "    \n",
    "    type_labels = []\n",
    "    for label in label_tensor:\n",
    "        char = label_to_class[int(label)]\n",
    "        if char.isdigit():\n",
    "            type_labels.append(0)\n",
    "        elif char.isupper():\n",
    "            type_labels.append(1)\n",
    "        else:\n",
    "            type_labels.append(2)\n",
    "    return torch.tensor(type_labels, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa091c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_type = get_type_label_tensor(y_train)\n",
    "y_test_type = get_type_label_tensor(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391d2ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train, y_train, y_train_type)\n",
    "test_dataset = TensorDataset(X_test, y_test, y_test_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f7f98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispielhafte Klasse-zu-Typ-Zuordnung: 0 = Groß, 1 = Klein, 2 = Ziffer\n",
    "def get_type_label_tensor(y):\n",
    "    type_labels = []\n",
    "    for label in y:\n",
    "        char = class_list[label]\n",
    "        if char.isdigit():\n",
    "            type_labels.append(2)\n",
    "        elif char.isupper():\n",
    "            type_labels.append(0)\n",
    "        else:\n",
    "            type_labels.append(1)\n",
    "    return torch.tensor(type_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbcbbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d475d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TypeClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TypeClassifier, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 7 * 7, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return F.softmax(self.fc(x), dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da19808",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModularClassifier(nn.Module):\n",
    "    def __init__(self, tm1, tm2, class_type_map):\n",
    "        super(ModularClassifier, self).__init__()\n",
    "        self.tm1 = tm1\n",
    "        self.tm2 = tm2\n",
    "        self.class_type_map = torch.tensor(class_type_map, dtype=torch.long)  # Länge 36\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_cls = self.tm1(x)  # shape (B, 36)\n",
    "        out_type = self.tm2(x)  # shape (B, 3)\n",
    "\n",
    "        type_probs = out_type[:, self.class_type_map.to(x.device)]  # shape (B, 36)\n",
    "        final_out = out_cls * type_probs  # Elementweise Multiplikation\n",
    "\n",
    "        return final_out, out_cls, out_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff7ec0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'isdigit'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m class_type_map = []\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m class_list:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mc\u001b[49m\u001b[43m.\u001b[49m\u001b[43misdigit\u001b[49m():\n\u001b[32m      5\u001b[39m         class_type_map.append(\u001b[32m2\u001b[39m)\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m c.isupper():\n",
      "\u001b[31mAttributeError\u001b[39m: 'int' object has no attribute 'isdigit'"
     ]
    }
   ],
   "source": [
    "# class_list = ['0', '1', ..., 'a', 'b', ...]\n",
    "class_type_map = []\n",
    "for c in class_list:\n",
    "    if c.isdigit():\n",
    "        class_type_map.append(2)\n",
    "    elif c.isupper():\n",
    "        class_type_map.append(0)\n",
    "    else:\n",
    "        class_type_map.append(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567bee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tm1 = ResNet18(num_classes=len(class_list))\n",
    "\n",
    "modular_model = ModularClassifier(\n",
    "    tm1,\n",
    "    tm2=TypeClassifier(),\n",
    "    class_type_map=class_type_map\n",
    ").to(device)\n",
    "\n",
    "criterion_cls = nn.CrossEntropyLoss()\n",
    "criterion_type = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(modular_model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce4c6de",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (36) must match the size of tensor b (0) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m labels_cls = labels_cls.to(device)\n\u001b[32m      8\u001b[39m labels_type = labels_type.to(device)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m final_out, out_cls, out_type = \u001b[43mmodular_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m loss_cls = criterion_cls(out_cls, labels_cls)\n\u001b[32m     13\u001b[39m loss_type = criterion_type(out_type, labels_type)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ML2Modularbeit/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ML2Modularbeit/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mModularClassifier.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     10\u001b[39m out_type = \u001b[38;5;28mself\u001b[39m.tm2(x)  \u001b[38;5;66;03m# shape (B, 3)\u001b[39;00m\n\u001b[32m     12\u001b[39m type_probs = out_type[:, \u001b[38;5;28mself\u001b[39m.class_type_map.to(x.device)]  \u001b[38;5;66;03m# shape (B, 36)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m final_out = \u001b[43mout_cls\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_probs\u001b[49m  \u001b[38;5;66;03m# Elementweise Multiplikation\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m final_out, out_cls, out_type\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (36) must match the size of tensor b (0) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    modular_model.train()\n",
    "    total_loss = 0.0  # ✅ richtig initialisieren\n",
    "\n",
    "    for images, labels_cls, labels_type in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels_cls = labels_cls.to(device)\n",
    "        labels_type = labels_type.to(device)\n",
    "\n",
    "        final_out, out_cls, out_type = modular_model(images)\n",
    "\n",
    "        loss_cls = criterion_cls(out_cls, labels_cls)\n",
    "        loss_type = criterion_type(out_type, labels_type)\n",
    "        loss = loss_cls + 0.5 * loss_type\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()  # ✅ jetzt ist total_loss eine float\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e2e7ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8fdf48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
